{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39292b04-30c3-49c2-8715-9b0a966e0737",
   "metadata": {},
   "source": [
    "# Optimizing Performance by using torchscript to jit-compile ODE model\n",
    "\n",
    "We make use of the details provided at https://pytorch.org/blog/optimizing-cuda-rnn-with-torchscript/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64443b5e-7410-4344-9b40-1cdc71d500f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'svg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "331c37ea-d9d5-4457-9ff1-23159c5dde43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchdiffeq\n",
    "from torch import nn\n",
    "from torch.nn import GRUCell\n",
    "import numpy as np\n",
    "from opt_einsum import contract\n",
    "from tqdm.auto import trange\n",
    "from typing import Union, Callable\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import odeint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdbf7257-1231-493f-8f1a-d565a0c79279",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('text', usetex=True)\n",
    "plt.rc('text.latex', preamble=r'\\usepackage{{amsmath}}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2362f548-c491-4693-a307-cb932d6a48f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_Lp(x, p=2):\n",
    "    x = np.abs(x)\n",
    "    if p==0:\n",
    "        # https://math.stackexchange.com/q/282271/99220\n",
    "        return stats.gmean(x, axis=None)\n",
    "    elif p==1:\n",
    "        return np.mean(x)\n",
    "    elif p==2:\n",
    "        return np.sqrt(np.mean(x**2))\n",
    "    elif p==np.inf:\n",
    "        return np.max(x)\n",
    "    else:\n",
    "        x = x.astype(np.float128)\n",
    "        return np.mean(x**p)**(1/p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c57bc597-e937-4996-a3a3-a1f953378e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_distribution(x, bins=50, log=True, ax=None):\n",
    "    x = np.array(x)\n",
    "    nans = np.isnan(x)\n",
    "    x = x[~nans]\n",
    "\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(10, 6), tight_layout=True)\n",
    "    \n",
    "    ax.grid(axis='x')\n",
    "    ax.set_axisbelow(True)\n",
    "\n",
    "    if log:\n",
    "        z = np.log10(x)\n",
    "        ax.set_xscale('log')\n",
    "        ax.set_yscale('log')\n",
    "        low = np.floor(np.quantile(z, 0.01))\n",
    "        high = np.quantile(z, 0.99)\n",
    "        x = x[(z>=low) & (z<=high)]\n",
    "        bins = np.logspace(low, high, num=bins, base=10)\n",
    "    ax.hist(x, bins=bins, density=True)\n",
    "    ax.text(.975, .975, \n",
    "       r\"\\begin{tabular}{ll}\" \\\n",
    "            + F\"NaNs   & {100*np.mean(nans):.2f}\\%\"   + r\" \\\\ \" \\\n",
    "            + F\"Mean   & {np.mean(x):.2e}\"          + r\" \\\\ \" \\\n",
    "            + F\"Median & {np.median(x):.2e}\"        + r\" \\\\ \" \\\n",
    "            + F\"Mode   & {stats.mode(x)[0][0]:.2e}\" + r\" \\\\ \" \\\n",
    "            + F\"stdev  & {np.std(x):.2e}\"           + r\" \\\\ \" \\\n",
    "        + r\"\\end{tabular}\",\n",
    "        transform=ax.transAxes, va='top', ha='right', snap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95c60ba3-1afb-4bff-9cfc-b026aded3f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinODECell(torch.jit.ScriptModule):\n",
    "    \"\"\"\n",
    "    Linear System module\n",
    "    \n",
    "    x' = Ax + Bu + w\n",
    "     y = Cx + Du + v\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_size, \n",
    "                 kernel_initialization: Union[torch.Tensor, Callable[int, torch.Tensor]] = None, \n",
    "                 homogeneous: bool =True, \n",
    "                 matrix_type: str =None,\n",
    "                 device=torch.device('cpu'),\n",
    "                 dtype=torch.float32,\n",
    "                ):\n",
    "        \"\"\"\n",
    "        kernel_initialization: torch.tensor or callable\n",
    "            either a tensor to assign to the kernel at initialization\n",
    "            or a callable f: int -> torch.Tensor|L\n",
    "        \"\"\"\n",
    "        super(LinODECell, self).__init__()\n",
    "        \n",
    "        \n",
    "        if kernel_initialization is None:\n",
    "            self.kernel_initialization = lambda: torch.randn(input_size, input_size)/np.sqrt(input_size)\n",
    "        elif callable(kernel_initialization):\n",
    "            self.kernel = lambda: torch.tensor(kernel_initialization(input_size))  \n",
    "        else:\n",
    "            self.kernel_initialization = lambda: torch.tensor(kernel_initialization)\n",
    "\n",
    "        self.kernel = nn.Parameter(self.kernel_initialization())    \n",
    "        \n",
    "        if not homogeneous:\n",
    "            self.bias = nn.Parameter(torch.randn(input_size))\n",
    "            raise NotImplementedError(\"Inhomogeneous Linear Model not implemented yet.\")\n",
    "            \n",
    "        self.to(device=device, dtype=dtype)\n",
    "       \n",
    "    @torch.jit.script_method\n",
    "    def forward(self, Δt, x):nput_size, hidden_size, \n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "        Δt: (...,)\n",
    "        x:  (..., M)\n",
    "        \n",
    "        Outputs:\n",
    "        xhat:  (..., M)\n",
    "        \n",
    "        \n",
    "        Forward using matrix exponential\n",
    "        # TODO: optimize if clauses away by changing definition in constructor.\n",
    "        \"\"\"\n",
    "        \n",
    "        AΔt    = torch.einsum('kl, ... -> ...kl', self.kernel, Δt)\n",
    "        expAΔt = torch.matrix_exp(AΔt)\n",
    "        xhat   = torch.einsum('...kl, ...l -> ...k', expAΔt, x)\n",
    "\n",
    "        return xhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aaa5bb56-f382-40de-9587-4a6becd6bb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinODE(torch.jit.ScriptModule):\n",
    "    def __init__(self, *cell_args, **cell_kwargs):\n",
    "        super(LinODE, self).__init__()\n",
    "        self.cell = LinODECell(*cell_args, **cell_kwargs)\n",
    "\n",
    "    @torch.jit.script_method\n",
    "    def forward(self, x0, T):\n",
    "        # type: (Tensor, Tensor) -> Tensor\n",
    "\n",
    "        ΔT = torch.diff(T)     \n",
    "        x = torch.jit.annotate(List[Tensor], [])    \n",
    "        x += [x0]\n",
    "    \n",
    "        for i, Δt in enumerate(ΔT):\n",
    "            x += [self.cell(Δt, x[-1])]\n",
    "            \n",
    "        return torch.stack(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df96357f-c9f7-499d-b240-82cc3bf27ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "HP = {\n",
    "    # Size of the latent state\n",
    "    'n_ode_gru_dims' : 6,\n",
    "    # Number of layers in ODE func in recognition ODE\n",
    "    'n_layers' : 1,\n",
    "    # Number of units per layer in ODE func\n",
    "    'n_units' : 100,\n",
    "    # nonlinearity used\n",
    "    'nonlinear' : nn.Tanh,\n",
    "    #\n",
    "    'concat_mask' : True,\n",
    "    # dimensionality of input\n",
    "    'input_dim' : n_dim,\n",
    "    # device: 'cpu' or 'cuda'\n",
    "    'device' : torch.device('cpu'),\n",
    "    # Number of units per layer in each of GRU update networks\n",
    "    'n_gru_units' : 100,\n",
    "    # measurement error\n",
    "    'obsrv_std' : 0.01,\n",
    "    #\n",
    "    'use_binary_classif' : False,\n",
    "    #\n",
    "    'train_classif_w_reconstr' : False,\n",
    "    #\n",
    "    'classif_per_tp' :  False,\n",
    "    # number of outputs\n",
    "    'n_labels' : 1,\n",
    "    # relative tolerance of ODE solver\n",
    "    'odeint_rtol': 1e-3,\n",
    "    # absolute tolereance of ODE solver\n",
    "    'odeint_atol': 1e-4,\n",
    "    # batch_size\n",
    "    'batch-size' : 50,\n",
    "    # learn-rate\n",
    "    'lr': 1e-2,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a78a4dbf-d2c9-4b68-8d2b-d98a0682582a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "def deep_update(d: dict, new: dict) -> dict:\n",
    "    \"\"\"\n",
    "    https://stackoverflow.com/a/30655448/9318372\n",
    "    Update a nested dictionary or similar mapping.\n",
    "    Modify ``source`` in place.\n",
    "    \"\"\"\n",
    "    for key, value in new.items():\n",
    "        if isinstance(value, collections.Mapping) and value:\n",
    "            d[key] = deep_update(d.get(key, {}), value)\n",
    "        else:\n",
    "            d[key] = new[key]\n",
    "    return d\n",
    "\n",
    "\n",
    "def deep_update_keys(d:dict, **new_kv) -> dict:\n",
    "    \"\"\"\n",
    "    Overrides values in nested dictionary.\n",
    "    For each key in a leaf dictionary (in the dictionary tree),\n",
    "    if the key appears in the new dict, its value is plugged in instead.\n",
    "    \"\"\"\n",
    "    for key, value in d.items():\n",
    "        if isinstance(value, collections.Mapping) and value:\n",
    "            d[key] = deep_update_keys(d.get(key, {}), **new_kv)\n",
    "        elif key in new_kv:\n",
    "            d[key] = new_kv[key]\n",
    "    return d\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72d33ee-f7a1-4dcb-9952-2c7caaee9d4c",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1184502f-2868-4627-a730-34606104715d",
   "metadata": {},
   "outputs": [],
   "source": [
    "HP = {\n",
    "    'GRUCell': {'input_size':None, 'bias' : True, 'hidden_size' : None},\n",
    "    'LinODE' : {'input_size':None, 'hidden_size': None, 'initialization': None},\n",
    "}\n",
    "deep_update_keys(HP['LinODE'], input_size=10)\n",
    "HP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f2a4729-54a8-4f10-b17b-15d5f617929a",
   "metadata": {},
   "outputs": [],
   "source": [
    "HP = {\n",
    "    'GRUCell': {'input_size':None, 'bias' : True, 'hidden_size' : None},\n",
    "    'LinODE' : {'input_size':None, 'hidden_size': None, 'initialization': None},\n",
    "}\n",
    "new_HP = {\n",
    "    'GRUCell': {'input_size':10, 'bias' : False, 'hidden_size' : 20},\n",
    "    'LinODE' : {'input_size':10},\n",
    "}\n",
    "deep_update(HP, new_HP)\n",
    "HP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72d0c7a-1cb1-4f83-90ed-f5fb704c797d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinODE_RNN(torch.jit.ScriptModule):\n",
    "    HP = {\n",
    "        'input_size'  : None,\n",
    "        'hidden_size' : None,\n",
    "        'GRUCell'     : {'input_size' : None, 'bias' : True, 'hidden_size' : None},\n",
    "        'LinODE'      : {\n",
    "            'input_size' : None, \n",
    "            'initialization': None},\n",
    "        'Decoder'     : {\n",
    "            'input_size': None, \n",
    "            'hidden_layers': 1,  \n",
    "            'activation': 'tanh', \n",
    "            'units': None, \n",
    "            'output_size': None\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    def __init__(self, input_size, HP = {}):\n",
    "        super(LinODE_RNN, self).__init__()\n",
    "        \n",
    "        # Setup default hyperparameters\n",
    "        hidden_size = 2*input_size\n",
    "        \n",
    "        deep_update_keys(self.HP, input_size=input_size, hidden_size=2*input_size)\n",
    "        \n",
    "        self.HP['LinODE']['input_size'] = HP['hidden_size']\n",
    "        self.HP['Decoder']['input_size'] = HP['hidden_size']\n",
    "        \n",
    "        deep_update_keys(self.HP['decoder'], {\n",
    "            'input_size': hidden_size, \n",
    "            'hidden_layers': 1,  \n",
    "            'activation': 'tanh', \n",
    "            'units': 2*input_size, \n",
    "            'output_size': input_size \n",
    "        })\n",
    "        \n",
    "        assert self.HP['GRUCell']['hidden_size'] == self.HP['input_size']\n",
    "        assert self.HP['Decoder']['input_size']  == self.HP['hidden_size']\n",
    "        assert self.HP['Decoder']['output_size'] == self.HP['input_size']\n",
    "\n",
    "        # Initialize the components\n",
    "        self.dynamic = LinODECell(**self.HP['LinODE'])    \n",
    "        self.filter  = GRUCell(**self.HP['GRUCell'])\n",
    "        self.encoder = None\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(self.HP['Decoder']['input_size'], self.HP['Decoder']['units']),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(self.HP['Decoder']['units'], self.HP['Decoder']['units']),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(self.HP['Decoder']['units'], self.HP['Decoder']['output_size']),\n",
    "        )\n",
    "    \n",
    "    @torch.jit.script_method\n",
    "    def forward(self, X, T):\n",
    "        # type: (Tensor, Tensor) -> Tensor\n",
    "        # shapes: X:  BATCH x SEQ_LEN x DIM\n",
    "        shape = X.shape\n",
    "        hidden_shape = (*X.shape, self.HP['hidden_size'])\n",
    "        \n",
    "        ΔT = torch.diff(T)\n",
    "        h = torch.zeros(hidden_shape)\n",
    "        Xhat = torch.empty_like(X)\n",
    "    \n",
    "        for i, Δt in enumerate(zip(h, ΔT)):\n",
    "            h_dash = self.dynamic(Δt, h[i])\n",
    "            h[i+1] = self.filter(h_dash, x[i+1])\n",
    "            \n",
    "        Xhat = self.decoder(h)\n",
    "            \n",
    "        return Xhat\n",
    "    \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
