{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing whether batch processing works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"PYTORCH_JIT\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datetime import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsdm.datasets import Electricity\n",
    "\n",
    "X = Electricity.dataset\n",
    "x = X.iloc[:100]\n",
    "t = X.index[:100]\n",
    "t = (t - t[0]) / np.timedelta64(1, \"h\")\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsteps = 100\n",
    "NDIM = 64\n",
    "BATCH_SIZE = 7\n",
    "OUTER_BATCH_SIZE = 3\n",
    "X = np.random.rand(nsteps, NDIM)\n",
    "T = np.sort(np.random.randn(nsteps))\n",
    "dtype = torch.float32\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor(X, dtype=dtype, device=device)\n",
    "T = torch.tensor(T, dtype=dtype, device=device)\n",
    "ΔT = torch.diff(T)\n",
    "Δt = ΔT[0]\n",
    "x0 = X[0]\n",
    "T_batch = torch.stack([T] * BATCH_SIZE)\n",
    "X_batch = torch.stack([X] * BATCH_SIZE)\n",
    "Δt_batch = torch.stack([Δt] * BATCH_SIZE)\n",
    "ΔT_batch = torch.stack([ΔT] * BATCH_SIZE)\n",
    "x0_batch = torch.stack([x0] * BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_graph(model, inputs):\n",
    "    with SummaryWriter(\n",
    "        f\"runs/{model.__class__.__name__}/{datetime.now().isoformat(timespec='seconds')}\"\n",
    "    ) as writer:\n",
    "        writer.add_graph(model, inputs, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from linodenet.models import LinearContraction\n",
    "\n",
    "model = LinearContraction(NDIM, 17)\n",
    "model.to(device=device, dtype=dtype)\n",
    "print([tuple(w.shape) for w in (x0, model(x0))])\n",
    "print([tuple(w.shape) for w in (x0_batch, model(x0_batch))])\n",
    "print([tuple(w.shape) for w in (X, model(X))])\n",
    "print([tuple(w.shape) for w in (X_batch, model(X_batch))])\n",
    "save_graph(model, x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from linodenet.models import iResNetBlock\n",
    "\n",
    "model = iResNetBlock(NDIM)\n",
    "model.to(device=device, dtype=dtype)\n",
    "print([tuple(w.shape) for w in (x0, model(x0))])\n",
    "print([tuple(w.shape) for w in (x0_batch, model(x0_batch))])\n",
    "print([tuple(w.shape) for w in (X, model(X))])\n",
    "print([tuple(w.shape) for w in (X_batch, model(X_batch))])\n",
    "save_graph(model, x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from linodenet.models import iResNet\n",
    "\n",
    "model = iResNet(NDIM)\n",
    "model.to(device=device, dtype=dtype)\n",
    "print([tuple(w.shape) for w in (x0, model(x0))])\n",
    "print([tuple(w.shape) for w in (x0_batch, model(x0_batch))])\n",
    "print([tuple(w.shape) for w in (X, model(X))])\n",
    "print([tuple(w.shape) for w in (X_batch, model(X_batch))])\n",
    "save_graph(model, x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from linodenet.models import LinODECell\n",
    "\n",
    "model = LinODECell(NDIM, kernel_projection=\"skew-symmetric\")\n",
    "model.to(device=device, dtype=dtype)\n",
    "print([tuple(w.shape) for w in (Δt, x0, model(Δt, x0))])\n",
    "print([tuple(w.shape) for w in (Δt_batch, x0_batch, model(Δt_batch, x0_batch))])\n",
    "save_graph(model, (Δt, x0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from linodenet.models import LinODE\n",
    "\n",
    "model = LinODE(NDIM, kernel_projection=\"skew-symmetric\")\n",
    "model.to(device=device, dtype=dtype)\n",
    "print([tuple(w.shape) for w in (T, x0, model(T, x0))])\n",
    "print([tuple(w.shape) for w in (T_batch, x0_batch, model(T_batch, x0_batch))])\n",
    "save_graph(model, (T, x0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from linodenet.models import LinODEnet\n",
    "\n",
    "model = LinODEnet(NDIM, 400, embedding_type=\"concat\")\n",
    "model.to(device=device, dtype=dtype)\n",
    "print([tuple(w.shape) for w in (T, X, model(T, X))])\n",
    "print([tuple(w.shape) for w in (T_batch, X_batch, model(T_batch, X_batch))])\n",
    "save_graph(model, (Δt, X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Batch Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_batch = torch.stack([T_batch] * OUTER_BATCH_SIZE)\n",
    "X_batch = torch.stack([X_batch] * OUTER_BATCH_SIZE)\n",
    "Δt_batch = torch.stack([Δt_batch] * OUTER_BATCH_SIZE)\n",
    "ΔT_batch = torch.stack([ΔT_batch] * OUTER_BATCH_SIZE)\n",
    "x0_batch = torch.stack([x0_batch] * OUTER_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from linodenet.models import LinearContraction\n",
    "\n",
    "model = LinearContraction(NDIM, 17)\n",
    "model.to(device=device, dtype=dtype)\n",
    "print([tuple(w.shape) for w in (x0, model(x0))])\n",
    "print([tuple(w.shape) for w in (x0_batch, model(x0_batch))])\n",
    "print([tuple(w.shape) for w in (X, model(X))])\n",
    "print([tuple(w.shape) for w in (X_batch, model(X_batch))])\n",
    "save_graph(model, x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from linodenet.models import iResNetBlock\n",
    "\n",
    "model = iResNetBlock(NDIM)\n",
    "model.to(device=device, dtype=dtype)\n",
    "print([tuple(w.shape) for w in (x0, model(x0))])\n",
    "print([tuple(w.shape) for w in (x0_batch, model(x0_batch))])\n",
    "print([tuple(w.shape) for w in (X, model(X))])\n",
    "print([tuple(w.shape) for w in (X_batch, model(X_batch))])\n",
    "save_graph(model, x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from linodenet.models import iResNet\n",
    "\n",
    "model = iResNet(NDIM)\n",
    "model.to(device=device, dtype=dtype)\n",
    "print([tuple(w.shape) for w in (x0, model(x0))])\n",
    "print([tuple(w.shape) for w in (x0_batch, model(x0_batch))])\n",
    "print([tuple(w.shape) for w in (X, model(X))])\n",
    "print([tuple(w.shape) for w in (X_batch, model(X_batch))])\n",
    "save_graph(model, x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from linodenet.models import LinODECell\n",
    "\n",
    "model = LinODECell(NDIM, kernel_projection=\"skew-symmetric\")\n",
    "model.to(device=device, dtype=dtype)\n",
    "print([tuple(w.shape) for w in (Δt, x0, model(Δt, x0))])\n",
    "print([tuple(w.shape) for w in (Δt_batch, x0_batch, model(Δt_batch, x0_batch))])\n",
    "save_graph(model, (Δt, x0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from linodenet.models import LinODE\n",
    "\n",
    "model = LinODE(NDIM, kernel_projection=\"skew-symmetric\")\n",
    "model.to(device=device, dtype=dtype)\n",
    "print([tuple(w.shape) for w in (T, x0, model(T, x0))])\n",
    "print([tuple(w.shape) for w in (T_batch, x0_batch, model(T_batch, x0_batch))])\n",
    "save_graph(model, (T, x0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from linodenet.models import LinODEnet\n",
    "\n",
    "model = LinODEnet(NDIM, 250)\n",
    "model.to(device=device, dtype=dtype)\n",
    "print([tuple(w.shape) for w in (T, X, model(T, X))])\n",
    "print([tuple(w.shape) for w in (T_batch, X_batch, model(T_batch, X_batch))])\n",
    "save_graph(model, (T, X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(model.modules())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(torch.nn.Linear(3, 4).register_forward_pre_hook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nn.Linear(3, 4).register_forward_pre_hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nn.Linear(3, 4).register_forward_pre_hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
