{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8913ec5b-3003-42e8-8eaf-e10418e9bdbc",
   "metadata": {},
   "source": [
    "# ODE-RNN with linear ODE instead of general\n",
    "\n",
    "- try with/without encoder\n",
    "- first run without missing values\n",
    "- later with missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3188e1b9-8ff4-48ca-babb-5b7ba981910c",
   "metadata": {},
   "source": [
    "```\n",
    "for i in 1,2,..., N:\n",
    "    h_i' = ODESolve(f, h_{i-1}, (t_{i-1}, t_i))\n",
    "    h_i = RNNCell(h_i', x_i)\n",
    "o_i = OutputNN(h_i) for all i...N\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64443b5e-7410-4344-9b40-1cdc71d500f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'svg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331c37ea-d9d5-4457-9ff1-23159c5dde43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import GRUCell\n",
    "import numpy as np\n",
    "from opt_einsum import contract\n",
    "from tqdm.auto import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b25cd2-383d-4def-b9ce-2be9d345f517",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71674ec7-51bd-4fcd-9991-cfe04db7d8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def visualize_distribution(x, bins=50, log=True, ax=None):\n",
    "    x = np.array(x)\n",
    "    x = x[~np.isnan(x)]\n",
    "\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(10, 6), tight_layout=True)\n",
    "\n",
    "    if log:\n",
    "        z = np.log10(x)\n",
    "        ax.set_xscale(\"log\")\n",
    "        ax.set_yscale(\"log\")\n",
    "        low = np.quantile(z, 0.01)\n",
    "        high = np.quantile(z, 0.99)\n",
    "        x = x[(z >= low) & (z <= high)]\n",
    "        bins = np.logspace(low, high, num=bins, base=10)\n",
    "    ax.hist(x, bins=bins, density=True)\n",
    "    ax.set_ylabel(\"density\")\n",
    "    print(\n",
    "        f\"median: {np.median(x):.2e}   mode:{stats.mode(x)[0][0]:.2e}   mean: {np.mean(x):.2e}  stdev:{np.std(x):.2e}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93c43de-a8e7-490c-8f79-8d22a95a9c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinODE(nn.Module):\n",
    "    \"\"\"\n",
    "    Linear System module\n",
    "\n",
    "    x' = Ax + Bu + w\n",
    "     y = Cx + Du + v\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size,\n",
    "        kernel_initialization: Union[torch.Tensor, Callable[int, torch.Tensor]] = None,\n",
    "        homogeneous: bool = True,\n",
    "        matrix_type: str = None,\n",
    "        device=torch.device(\"cpu\"),\n",
    "        dtype=torch.float32,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        kernel_initialization: torch.tensor or callable\n",
    "            either a tensor to assign to the kernel at initialization\n",
    "            or a callable f: int -> torch.Tensor|L\n",
    "        \"\"\"\n",
    "        super(LinODE, self).__init__()\n",
    "\n",
    "        if kernel_initialization is None:\n",
    "            self.kernel_initialization = lambda: torch.randn(\n",
    "                input_size, input_size\n",
    "            ) / np.sqrt(input_size)\n",
    "        elif callable(kernel_initialization):\n",
    "            self.kernel = lambda: torch.tensor(kernel_initialization(input_size))\n",
    "        else:\n",
    "            self.kernel_initialization = lambda: torch.tensor(kernel_initialization)\n",
    "\n",
    "        self.kernel = nn.Parameter(self.kernel_initialization())\n",
    "\n",
    "        if not homogeneous:\n",
    "            self.bias = nn.Parameter(torch.randn(input_size))\n",
    "            raise NotImplementedError(\"Inhomogeneous Linear Model not implemented yet.\")\n",
    "\n",
    "        self.to(device=device, dtype=dtype)\n",
    "\n",
    "    def forward(self, Δt, x):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "        Δt: (...,)\n",
    "        x:  (..., M)\n",
    "\n",
    "        Outputs:\n",
    "        xhat:  (..., M)\n",
    "\n",
    "\n",
    "        Forward using matrix exponential\n",
    "        # TODO: optimize if clauses away by changing definition in constructor.\n",
    "        \"\"\"\n",
    "        #         Δt = torch.diff(t)\n",
    "        #         print(Δt.shape, x.shape)\n",
    "        AΔt = contract(\"kl, ... -> ...kl\", self.kernel, Δt)\n",
    "        expAΔt = torch.matrix_exp(AΔt)\n",
    "        #         print(expAΔt.shape)\n",
    "        xhat = contract(\"...kl, ...l -> ...k\", expAΔt, x)\n",
    "\n",
    "        return xhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2362f548-c491-4693-a307-cb932d6a48f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_Lp(x, p=2):\n",
    "    x = np.abs(x)\n",
    "    if p == 0:\n",
    "        # https://math.stackexchange.com/q/282271/99220\n",
    "        return stats.gmean(x, axis=None)\n",
    "    elif p == 1:\n",
    "        return np.mean(x)\n",
    "    elif p == 2:\n",
    "        return np.sqrt(np.mean(x**2))\n",
    "    elif p == np.inf:\n",
    "        return np.max(x)\n",
    "    else:\n",
    "        x = x.astype(np.float128)\n",
    "        return np.mean(x**p) ** (1 / p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b352ccaa-9e86-4aac-9e37-30910510af13",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = np.random.randint(low=20, high=1000)\n",
    "dim = np.random.randint(low=2, high=100)\n",
    "t0, t1 = np.random.uniform(low=-10, high=10, size=(2,))\n",
    "A = np.random.randn(dim, dim)\n",
    "x0 = np.random.randn(dim)\n",
    "T = np.random.uniform(low=t0, high=t1, size=num - 2)\n",
    "T = np.sort([t0, *T, t1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512733a9-e1d6-4153-95ca-479bf5332969",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = torch.tensor(T).to(dtype=torch.float32)\n",
    "ΔT = torch.diff(T).to(dtype=torch.float32)\n",
    "Xhat = torch.empty(num, dim).to(dtype=torch.float32)\n",
    "Xhat[0] = torch.tensor(x0).to(dtype=torch.float32)\n",
    "model = LinODECell(input_size=dim, kernel_initialization=A).to(dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62f98ff-e59b-49dd-8c06-708ad8f0e18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model(ΔT[0], Xhat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa70425d-7a59-4ff5-91b6-eb07ea5f16db",
   "metadata": {},
   "outputs": [],
   "source": [
    "del torch_linodeint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0ddcc4-11bc-4f50-911b-38f9b8ab2c49",
   "metadata": {},
   "source": [
    "# Optimizing the RNN implementation\n",
    "\n",
    "We make use of the details provided at https://pytorch.org/blog/optimizing-cuda-rnn-with-torchscript/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6a9696-01ce-4549-97b2-24b4d89c358e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187e3dfd-19e0-4618-806a-0836b2d2e9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinODECell(jit.ScriptModule):\n",
    "    \"\"\"\n",
    "    Linear System module\n",
    "\n",
    "    x' = Ax + Bu + w\n",
    "     y = Cx + Du + v\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size,\n",
    "        kernel_initialization: Union[torch.Tensor, Callable[int, torch.Tensor]] = None,\n",
    "        homogeneous: bool = True,\n",
    "        matrix_type: str = None,\n",
    "        device=torch.device(\"cpu\"),\n",
    "        dtype=torch.float32,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        kernel_initialization: torch.tensor or callable\n",
    "            either a tensor to assign to the kernel at initialization\n",
    "            or a callable f: int -> torch.Tensor|L\n",
    "        \"\"\"\n",
    "        super(LinODECell, self).__init__()\n",
    "\n",
    "        if kernel_initialization is None:\n",
    "            self.kernel_initialization = lambda: torch.randn(\n",
    "                input_size, input_size\n",
    "            ) / np.sqrt(input_size)\n",
    "        elif callable(kernel_initialization):\n",
    "            self.kernel = lambda: torch.tensor(kernel_initialization(input_size))\n",
    "        else:\n",
    "            self.kernel_initialization = lambda: torch.tensor(kernel_initialization)\n",
    "\n",
    "        self.kernel = nn.Parameter(self.kernel_initialization())\n",
    "\n",
    "        if not homogeneous:\n",
    "            self.bias = nn.Parameter(torch.randn(input_size))\n",
    "            raise NotImplementedError(\"Inhomogeneous Linear Model not implemented yet.\")\n",
    "\n",
    "        self.to(device=device, dtype=dtype)\n",
    "\n",
    "    @jit.script_method\n",
    "    def forward(self, Δt, x):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "        Δt: (...,)\n",
    "        x:  (..., M)\n",
    "\n",
    "        Outputs:\n",
    "        xhat:  (..., M)\n",
    "\n",
    "\n",
    "        Forward using matrix exponential\n",
    "        # TODO: optimize if clauses away by changing definition in constructor.\n",
    "        \"\"\"\n",
    "\n",
    "        AΔt = torch.einsum(\"kl, ... -> ...kl\", self.kernel, Δt)\n",
    "        expAΔt = torch.matrix_exp(AΔt)\n",
    "        xhat = torch.einsum(\"...kl, ...l -> ...k\", expAΔt, x)\n",
    "\n",
    "        return xhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe80c5a-3fb3-40ac-a23d-41c5d224bf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinODECell(input_size=dim, kernel_initialization=A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c3fc2b-6721-4a3a-808c-b7c3eadb2128",
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_linodeint(model, x0, T):\n",
    "    ΔT = torch.diff(T)\n",
    "    Xhat = torch.empty(len(T), len(x0))\n",
    "\n",
    "    results = [x0]\n",
    "    Xhat[0] = torch.tensor(x0)\n",
    "\n",
    "    for i, Δt in enumerate(ΔT):\n",
    "        results.append(model(Δt, results[-1]))\n",
    "    #         Xhat[i+1] = model(Δt, Xhat[i])\n",
    "    return Xhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8daa8845-6242-4c9d-b49f-8f1f398aa692",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.jit.script\n",
    "def torch_linodeint(model, x0, T):\n",
    "    ΔT = torch.diff(T)\n",
    "    Xhat = torch.empty(len(T), len(x0))\n",
    "\n",
    "    results = [x0]\n",
    "    Xhat[0] = torch.tensor(x0)\n",
    "\n",
    "    for i, Δt in enumerate(ΔT):\n",
    "        results.append(model(Δt, results[-1]))\n",
    "    #         Xhat[i+1] = model(Δt, Xhat[i])\n",
    "    return Xhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5109ab7e-ab24-4fdc-ad68-b54de9d16855",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_LinODE(dim=None, num=None, tol=1e-3, precision=\"single\", relative_error=True):\n",
    "    from scipy.integrate import odeint\n",
    "\n",
    "    if precision == \"single\":\n",
    "        eps = 2**-24\n",
    "        numpy_dtype = np.float32\n",
    "        torch_dtype = torch.float32\n",
    "    elif precision == \"double\":\n",
    "        eps = 2**-53\n",
    "        numpy_dtype = np.float64\n",
    "        torch_dtype = torch.float64\n",
    "    else:\n",
    "        raise ValueError\n",
    "\n",
    "    num = np.random.randint(low=20, high=1000) or num\n",
    "    dim = np.random.randint(low=2, high=100) or dim\n",
    "    t0, t1 = np.random.uniform(low=-10, high=10, size=(2,)).astype(numpy_dtype)\n",
    "    A = np.random.randn(dim, dim).astype(numpy_dtype)\n",
    "    x0 = np.random.randn(dim).astype(numpy_dtype)\n",
    "    T = np.random.uniform(low=t0, high=t1, size=num - 2).astype(numpy_dtype)\n",
    "    T = np.sort([t0, *T, t1]).astype(numpy_dtype)\n",
    "    func = lambda t, x: A @ x\n",
    "\n",
    "    X = odeint(func, x0, T, tfirst=True)\n",
    "\n",
    "    model = LinODE(input_size=dim, kernel_initialization=A, dtype=torch_dtype)\n",
    "    ΔT = torch.diff(torch.tensor(T))\n",
    "    Xhat = torch.empty(num, dim, dtype=torch_dtype)\n",
    "    Xhat[0] = torch.tensor(x0)\n",
    "\n",
    "    for i, Δt in enumerate(ΔT):\n",
    "        Xhat[i + 1] = model(Δt, Xhat[i])\n",
    "\n",
    "    Xhat = Xhat.detach().cpu().numpy()\n",
    "\n",
    "    err = np.abs(X - Xhat)\n",
    "\n",
    "    if relative_error:\n",
    "        err /= np.abs(X) + eps\n",
    "\n",
    "    return np.array([scaled_Lp(err, p=p) for p in (1, 2, np.inf)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3972139-0f34-4286-8c54-7bc899023db8",
   "metadata": {},
   "source": [
    "## Checking LinODE error\n",
    "\n",
    "We compare results from our LinODE against scipy's odeint, averaged across different number of dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671495d1-1537-49dc-81cd-aa072053c7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "errs = np.array([test_LinODE() for _ in trange(1_000)]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd96c3de-22f2-4f9a-8521-3985f0c47b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(\n",
    "    ncols=3, figsize=(12, 3), tight_layout=True, sharey=True, sharex=True\n",
    ")\n",
    "\n",
    "for i, p in enumerate((1, 2, np.inf)):\n",
    "    visualize_distribution(errs[i], log=True, ax=ax[i])\n",
    "    ax[i].set_title(f\"scaled, relative L{p} error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992fd045-ae33-4ea3-90b6-ee357f69906d",
   "metadata": {},
   "outputs": [],
   "source": [
    "errs = np.array([test_LinODE(precision=\"double\") for _ in trange(1_000)]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a81b34-6dfb-47ad-811c-c434ec8fa9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(\n",
    "    ncols=3, figsize=(12, 3), tight_layout=True, sharey=True, sharex=True\n",
    ")\n",
    "\n",
    "for i, p in enumerate((1, 2, np.inf)):\n",
    "    visualize_distribution(errs[i], log=True, ax=ax[i])\n",
    "    ax[i].set_title(f\"scaled, relative L{p} error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342d73bc-3b7f-41e1-9ba0-e1b642e3a635",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_LinODEA(dim=None, num=None, tol=1e-3, precision=\"single\", relative_error=True):\n",
    "    from scipy.integrate import odeint\n",
    "\n",
    "    if precision == \"single\":\n",
    "        eps = 2**-24\n",
    "        numpy_dtype = np.float32\n",
    "        torch_dtype = torch.float32\n",
    "    elif precision == \"double\":\n",
    "        eps = 2**-53\n",
    "        numpy_dtype = np.float64\n",
    "        torch_dtype = torch.float64\n",
    "    else:\n",
    "        raise ValueError\n",
    "\n",
    "    num = np.random.randint(low=20, high=1000) or num\n",
    "    dim = np.random.randint(low=2, high=100) or dim\n",
    "    t0, t1 = np.random.uniform(low=-10, high=10, size=(2,)).astype(numpy_dtype)\n",
    "    A = np.random.randn(dim, dim).astype(numpy_dtype)\n",
    "    x0 = np.random.randn(dim).astype(numpy_dtype)\n",
    "    T = np.random.uniform(low=t0, high=t1, size=num - 2).astype(numpy_dtype)\n",
    "    T = np.sort([t0, *T, t1]).astype(numpy_dtype)\n",
    "    func = lambda t, x: A @ x\n",
    "\n",
    "    X = odeint(func, x0, T, tfirst=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9be4e4-e7c6-4e93-850c-8d2a52ca2a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = [test_LinODEA() for k in trange(1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9c4171-7180-4deb-a43b-44605e387f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_LinODEB(dim=None, num=None, tol=1e-3, precision=\"single\", relative_error=True):\n",
    "    from scipy.integrate import odeint\n",
    "\n",
    "    if precision == \"single\":\n",
    "        eps = 2**-24\n",
    "        numpy_dtype = np.float32\n",
    "        torch_dtype = torch.float32\n",
    "    elif precision == \"double\":\n",
    "        eps = 2**-53\n",
    "        numpy_dtype = np.float64\n",
    "        torch_dtype = torch.float64\n",
    "    else:\n",
    "        raise ValueError\n",
    "\n",
    "    num = np.random.randint(low=20, high=1000) or num\n",
    "    dim = np.random.randint(low=2, high=100) or dim\n",
    "    t0, t1 = np.random.uniform(low=-10, high=10, size=(2,)).astype(numpy_dtype)\n",
    "    A = np.random.randn(dim, dim).astype(numpy_dtype)\n",
    "    x0 = np.random.randn(dim).astype(numpy_dtype)\n",
    "    T = np.random.uniform(low=t0, high=t1, size=num - 2).astype(numpy_dtype)\n",
    "    T = np.sort([t0, *T, t1]).astype(numpy_dtype)\n",
    "\n",
    "    model = LinODE(input_size=dim, kernel_initialization=A, dtype=torch_dtype).to(\n",
    "        device=torch.device(\"cuda\")\n",
    "    )\n",
    "    ΔT = torch.diff(torch.tensor(T)).to(device=torch.device(\"cuda\"))\n",
    "    Xhat = torch.empty(num, dim, dtype=torch_dtype).to(device=torch.device(\"cuda\"))\n",
    "    Xhat[0] = torch.tensor(x0).to(device=torch.device(\"cuda\"))\n",
    "\n",
    "    for i, Δt in enumerate(ΔT):\n",
    "        Xhat[i + 1] = model(Δt, Xhat[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b40cdf-e23e-45b8-a644-ea3b1cb5ca4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = [test_LinODEB() for k in trange(1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c4cd14-1e92-4c99-9593-0c006c429e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb33e4f5-91e0-4191-bd60-1d72a5a234fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_linode:\n",
    "    from scipy.integrate import odeint\n",
    "    n = np.random.randint(low=1, high=100)\n",
    "    t0, t1 = np.random.uniform(low=-10, high=10, size=(2,))\n",
    "    A = np.random.randn(n,n)\n",
    "    x0 = np.random.randn(n)\n",
    "    T = np.linspace(t0, t1)\n",
    "    func = lambda t, x: A@x\n",
    "    x = odeint(func, x0, T, tfirst=True)\n",
    "    \n",
    "    model = LinODE(input_size=n)\n",
    "    model.kernel =torch.from_numpy(A)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0e49fc-79ad-400d-b768-e038254254a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttrDict(dict):\n",
    "    # https://stackoverflow.com/a/14620633/9318372\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(AttrDict, self).__init__(*args, **kwargs)\n",
    "        self.__dict__ = self\n",
    "\n",
    "\n",
    "d = AttrDict({\"k\": 1, \"l\": 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467f7a6d-2afe-4cd3-9706-88b1e3f11a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "\n",
    "def deep_update(source: dict, overrides: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Update a nested dictionary or similar mapping.\n",
    "    Modify ``source`` in place.\n",
    "    Reference: https://stackoverflow.com/a/30655448/9318372\n",
    "    \"\"\"\n",
    "    for key, value in overrides.iteritems():\n",
    "        if isinstance(value, collections.Mapping) and value:\n",
    "            returned = deep_update(source.get(key, {}), value)\n",
    "            source[key] = returned\n",
    "        else:\n",
    "            source[key] = overrides[key]\n",
    "    return source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9a317b-b86b-4a5e-a0cf-e1771b3a8f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinODE_RNN(nn.Module):\n",
    "    # default hyperparameters\n",
    "    HP = {\n",
    "        # what model to use for the reccurent cell. Options: LSTMCell, RNNCell, GRUCell\n",
    "        'Cell': nn.GRUCell,\n",
    "        # Reccurent Cell Options. See\n",
    "        'CellOptions' : {'input_size': None, 'hidden_size' : None, 'bias' : True},\n",
    "        # Linear ODE parameters.\n",
    "        'LinODE' :  {'input_size': None, 'initialization': None, 'matrix_type': None, 'homogeneous'=True},\n",
    "    }\n",
    "    \n",
    "    def __set_HP():\n",
    "        self.HP['LinODE']['hidden_size']\n",
    "    \n",
    "    def __init__(self, input_size, HP: dict):\n",
    "        self.__set_HP(input_size, HP: dict)\n",
    "        self.init_HP()\n",
    "        self.dynamics = LinODE(**HP['LinODE'])\n",
    "        self.encoder = \n",
    "        self.decoder = \n",
    "        self.filter = \n",
    "        \n",
    "        \n",
    "    def forward(self):\n",
    "        \"\"\"c\n",
    "        input: t: tensor shape (..., N,)\n",
    "            Observation timepoints corresponding to the observed values\n",
    "        input: x: tensor shape (..., N, M) dtype: float. \n",
    "            Observed data, NaN indicates Missing values\n",
    "        input:\n",
    "        output: xhat: tensor shape (..., N, M)\n",
    "            Predicted values. The values may differ from x for non-NaN entries, since the model assumes that observational data is noisy.\n",
    "            Q: Does this make any sense for categorical data? Not really..., but one can use sigmoid for example.\n",
    "        \"\"\"\n",
    "        \n",
    "        xhat = None\n",
    "        \n",
    "        return xhat\n",
    "    \n",
    "    def predict(self, t, x):\n",
    "        xhat = self(t, x)\n",
    "        \n",
    "        # TODO: treat categorical features.\n",
    "        \n",
    "        return xhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62dd0893-6649-466f-b258-5ad7f6e59d9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8a0f2a-0304-4c68-bc95-07f35a214971",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.random.choice([True, False], size=(5, 6))\n",
    "np.where(mask, np.random.randn(5, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cd0fef-fbd7-4a38-9dd3-eaa11a1ba48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = AttrDict()\n",
    "d.update({\"items\": [\"jacket\", \"necktie\", \"trousers\"]})\n",
    "d.items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a2cac6-dd0b-4b1d-8660-514967ec3cfe",
   "metadata": {},
   "source": [
    "How to handle input? We have multiple Options:\n",
    "\n",
    "1. Input $t_\\text{obs}$, $x_\\text{obs}$, and $t_\\text{predict}$, return $x_\\text{predict}$\n",
    "    - similar to regular ODESELVE input, but with many time observations instead of single initial condition.\n",
    "2. Input $t_\\text{obs+predict}$, $x_\\text{obs}$, fill $x$ with nan values at prediction points (reduce problem to imputation task)\n",
    "3. Input $t$, $x$, $u$. The controls $u$ can occur at future time points (pre-scheduled) controls\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01bfe37-31f6-48dc-a71e-429cd990ec4e",
   "metadata": {},
   "source": [
    "### Question? How to handle initial hidden state & initial state estimation in RNN?\n",
    "\n",
    "1. Initialize with zero or randomly (kinda dumb, but has to do for now)\n",
    "2. Initialize through initializer network, \n",
    "    - small deepset / Time series set function network\n",
    "    - ODE-RNN encoder like in Latent-ODE encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50640a4e-56ec-4fbb-b5ab-ce62380dfd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinODERNN(nn.Module):\n",
    "    # default hyperparameters\n",
    "    HP = {\n",
    "        'GRUCell' : {'bias' : True, 'hidden_size' : None},\n",
    "        'LinODE' : {'hidden_size': None, initialization: 'None'}\n",
    "    }\n",
    "    \n",
    "    def __set_HP()\n",
    "    \n",
    "    def __init__(self, input_size, **hyperparameters):\n",
    "        self.__set_HP(**hyperparameters)\n",
    "        self.init_HP()\n",
    "        self.GRUCell = nn.GRUCell()\n",
    "        self.LinODE = LinODE()\n",
    "        \n",
    "    def forward(self):\n",
    "        \"\"\"c\n",
    "        input: t: tensor shape (..., N,)\n",
    "            Observation timepoints corresponding to the observed values\n",
    "        input: x: tensor shape (..., N, M) dtype: float. \n",
    "            Observed data, NaN indicates Missing values\n",
    "        input:\n",
    "        output: xhat: tensor shape (..., N, M)\n",
    "            Predicted values. The values may differ from x for non-NaN entries, since the model assumes that observational data is noisy.\n",
    "            Q: Does this make any sense for categorical data? Not really..., but one can use sigmoid for example.\n",
    "        \"\"\"\n",
    "        \n",
    "        xhat = None\n",
    "        \n",
    "        return xhat\n",
    "    \n",
    "    def predict(self, t, x):\n",
    "        xhat = self(t, x)\n",
    "        \n",
    "        # TODO: treat categorical features.\n",
    "        \n",
    "        return xhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033574dd-8d62-4ce0-8ed5-e47b94062104",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16511690-32f1-4c66-9684-c0716048b968",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "N = 100_000\n",
    "n = 20\n",
    "\n",
    "A = np.random.randn(N, n, n)\n",
    "symA = (A + np.einsum(\"ijk-> ikj\", A)) / 2\n",
    "skewA = (A - np.einsum(\"ijk-> ikj\", A)) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cb2a5d-24c6-449d-8509-d29b45227e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "conds = np.linalg.cond(A)\n",
    "symconds = np.linalg.cond(symA)\n",
    "skewconds = np.linalg.cond(skewA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ee7ce1-7dbe-403e-b20d-f65c60169d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "\n",
    "def visualize_distribution(x, bins=100, log=True, ax=None):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(10, 6), tight_layout=True)\n",
    "\n",
    "    if log:\n",
    "        x = np.log10(x)\n",
    "        ax.set_xscale(\"log\")\n",
    "        ax.set_yscale(\"log\")\n",
    "        bins = np.logspace(np.floor(np.min(x)), np.ceil(np.max(x)), num=bins, base=10)\n",
    "    ax.hist(conds, bins=bins, density=True)\n",
    "    print(\n",
    "        f\"median: {np.median(x):.2}   mode:{stats.mode(x)[0][0]:.2}   mean: {np.mean(x):.2}  stdev:{np.std(x):.2}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30499228-84a0-4953-b367-9714acf03e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(\n",
    "    ncols=3, figsize=(12, 4), tight_layout=True, sharex=True, sharey=True\n",
    ")\n",
    "visualize_distribution(conds, ax=ax[0])\n",
    "visualize_distribution(symconds, ax=ax[1])\n",
    "visualize_distribution(skewconds, ax=ax[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f104e397-f2e7-4c69-be46-8837c87a5a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.init.kaiming_normal_(torch.empty(10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008af0b5-a872-47ae-81b3-41e589c85848",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_matrix(input_size, kind=None):\n",
    "    \"\"\"\n",
    "    kind options:\n",
    "    symmetric,\n",
    "    skew symmetric,\n",
    "    orthogonal,\n",
    "    normal,\n",
    "    \"\"\"\n",
    "\n",
    "    A = nn.init.kaiming_normal_(torch.empty(input_size, input_size))\n",
    "\n",
    "    if kind == \"symmetric\":\n",
    "        return (A + A.T) / 2\n",
    "    if kind == \"skew-symmetric\":\n",
    "        return (A - A.T) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffa14dc-e894-4044-9e9d-7318fe919a06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21bf384-0897-412d-8c05-623d3fe666b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014a22a8-aff6-490e-b98c-67e5f8da4a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "?GRUCell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b305ff24-8f3a-48f9-ab44-af1b84eda62b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
