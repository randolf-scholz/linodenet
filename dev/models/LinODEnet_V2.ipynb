{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20191951-beec-414a-b3c6-89dca8277ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InteractiveShell.ast_node_interactivity='last_expr_or_assign'  # always print last expr.\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4924c28-4ed7-41d4-a961-bd4ece3c62bd",
   "metadata": {},
   "source": [
    "## LinODEnet v2\n",
    "\n",
    "\n",
    "We add special treatment of covariates $u$\n",
    "\n",
    "Inhomogeneous Linear Equation\n",
    "\n",
    "$$ \\dot{x}(t) = Ax(t) + f(t) $$\n",
    "\n",
    "\n",
    "E.g. Linear State Space System\n",
    "\n",
    "$$ \\dot{x}(t) = Ax(t) + Bu(t) $$\n",
    "\n",
    "Solution:\n",
    "\n",
    "$$\\begin{aligned} \n",
    "     x(t) &=  e^{A(t-t_0)}x_{t_0} + \\int_{t_0}^t e^{A(t-s)} f(s) ds \n",
    "\\\\   x(t+‚àÜt) &=  e^{A‚àÜt}x_t + \\int_{t}^{t+‚àÜt} e^{A(t+‚àÜt-s)} f(s) ds \n",
    "\\\\   x(t+‚àÜt) &=  e^{A‚àÜt}x_t + \\int_{0}^{‚àÜt} e^{A(‚àÜt-‚àÜœÑ)} f(t+{‚àÜœÑ}) d{‚àÜœÑ}  \\qquad s=t+‚àÜœÑ\n",
    "\\end{aligned}$$\n",
    "\n",
    "\n",
    "Special cases:\n",
    "\n",
    "1. $f(t) = b$ constant in $t$, then $‚áùx(t+‚àÜt)=e^{A‚àÜt}x_t + \\frac{e^{A‚àÜt}-ùïÄ}{A}b$\n",
    "2. $f(t) = a‚ãÖt + b$ linear in $t$, then ?\n",
    "\n",
    "Generalized Exponential Integral:\n",
    "\n",
    "\n",
    "$$ E_n(x) = ‚à´ \\frac{e^{-xt}}{t^n} dt = x^{n-1} Œì(1-n,x)$$\n",
    "\n",
    "Misra Function: $œÜ_m(x) = E_{-m}(x)$\n",
    "\n",
    "Block matrix trick:\n",
    "\n",
    "$$ \\exp \\bigg(\\begin{bmatrix}A& B \\\\ 0 & 0 \\end{bmatrix}‚ãÖt\\bigg) \n",
    "= \\begin{bmatrix}e^{At} & ‚à´_0^t e^{AœÑ}BdœÑ \\\\ 0 & ùïÄ \\end{bmatrix}\n",
    "= \\begin{bmatrix}e^{At} & œÜ_1(At)B \\\\ 0 & ùïÄ \\end{bmatrix}\n",
    "$$ \n",
    "\n",
    "\n",
    "\n",
    "Formula: (Higham)\n",
    "\n",
    "\n",
    "$$ x(t+‚àÜt) = e^{A‚àÜt}x_t + ‚àë_{k=1}^‚àû œÜ_k(A‚àÜt) u_k ‚àÜt^k \\qquad  u_k = ùêÉ^{k-1}f(t)$$\n",
    "\n",
    "Recursion:  $$ \\varphi_{\\ell}(z)=z \\varphi_{\\ell+1}(z)+\\frac{1}{\\ell !}, \\quad \\varphi_{0}(z)=e^{z}$$\n",
    "\n",
    "So: $$œÜ_1(At) = \\frac{e^{At}-ùïÄ}{At} \\qquad œÜ_2(At) = \\frac{e^{At} -At -ùïÄ}{(At)^2} \\qquad œÜ_3(At) = \\frac{e^{At}-¬Ω(At)^2 -At -ùïÄ}{(At)^3} $$\n",
    "\n",
    "Truncating at $K=2$, i.e. $f(t)=œâ‚ãÖt+b$\n",
    "\n",
    "\n",
    "$$ x(t+‚àÜt) = e^{A‚àÜt}x_t + \\frac{e^{A‚àÜt}-ùïÄ}{A {‚àÜt}}{‚àÜt} b +  \\frac{e^{A‚àÜt}-A-ùïÄ}{(A {‚àÜt})^2}{‚àÜt}^2œâ$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc998a24-debf-48f6-879b-76d83cab95e9",
   "metadata": {},
   "source": [
    "## Remark\n",
    "\n",
    "The block matrix formula proves that, in some sense, we do not need to separately encode the predictions and the covariates.\n",
    "A larger latent space is sufficient to model the same thing as inhomogeneous linear ODE, or even polynomial components.\n",
    "\n",
    "\n",
    "### Theorem:\n",
    "\n",
    "If $p(t)$ is polynomial, then:\n",
    "\n",
    "$$ \\dot{x} = Ax(t) + p(t) ‚ü∫ \\dot{z} = \\tilde{A} z(t)$$ \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e7afbc-0b6c-405e-98be-e537434fd573",
   "metadata": {},
   "outputs": [],
   "source": [
    "import linodenet\n",
    "from linodenet.models.system import LinODECell\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b7f6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from typing import Any, Final, Optional, TypeVar\n",
    "\n",
    "import torch\n",
    "from linodenet.initializations.functional import FunctionalInitialization\n",
    "from linodenet.models.embeddings import ConcatEmbedding, ConcatProjection\n",
    "from linodenet.models.encoders import iResNet\n",
    "from linodenet.models.filters import Filter, RecurrentCellFilter\n",
    "from linodenet.models.system import LinODECell\n",
    "from linodenet.projections import Projection\n",
    "from linodenet.util import autojit, deep_dict_update, initialize_from_config\n",
    "from torch import Tensor, jit, nn\n",
    "\n",
    "__logger__ = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "# @autojit\n",
    "class LinODEnet(nn.Module):\n",
    "    r\"\"\"Linear ODE Network is a FESD model.\n",
    "\n",
    "    +---------------------------------------------------+--------------------------------------+\n",
    "    | Component                                         | Formula                              |\n",
    "    +===================================================+======================================+\n",
    "    | Filter  `F` (default: :class:`~torch.nn.GRUCell`) | `\\hat x_i' = F(\\hat x_i, x_i)`       |\n",
    "    +---------------------------------------------------+--------------------------------------+\n",
    "    | Encoder `œï` (default: :class:`~iResNet`)          | `\\hat z_i' = œï(\\hat x_i')`           |\n",
    "    +---------------------------------------------------+--------------------------------------+\n",
    "    | System  `S` (default: :class:`~LinODECell`)       | `\\hat z_{i+1} = S(\\hat z_i', Œî t_i)` |\n",
    "    +---------------------------------------------------+--------------------------------------+\n",
    "    | Decoder `œÄ` (default: :class:`~iResNet`)          | `\\hat x_{i+1}  =  œÄ(\\hat z_{i+1})`   |\n",
    "    +---------------------------------------------------+--------------------------------------+\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    input_size:  int\n",
    "        The dimensionality of the input space.\n",
    "    hidden_size: int\n",
    "        The dimensionality of the latent space.\n",
    "    output_size: int\n",
    "        The dimensionality of the output space.\n",
    "    ZERO: Tensor\n",
    "        BUFFER: A constant tensor of value float(0.0)\n",
    "    xhat_pre: Tensor\n",
    "        BUFFER: Stores pre-jump values.\n",
    "    xhat_post: Tensor\n",
    "        BUFFER: Stores post-jump values.\n",
    "    zhat_pre: Tensor\n",
    "        BUFFER: Stores pre-jump latent values.\n",
    "    zhat_post: Tensor\n",
    "        BUFFER: Stores post-jump latent values.\n",
    "    kernel: Tensor\n",
    "        PARAM: The system matrix of the linear ODE component.\n",
    "    encoder: nn.Module\n",
    "        MODULE: Responsible for embedding `xÃÇ‚ÜízÃÇ`.\n",
    "    embedding: nn.Module\n",
    "        MODULE: Responsible for embedding `xÃÇ‚ÜízÃÇ`.\n",
    "    system: nn.Module\n",
    "        MODULE: Responsible for propagating `zÃÇ_t‚ÜízÃÇ_{t+‚àÜt}`.\n",
    "    decoder: nn.Module\n",
    "        MODULE: Responsible for projecting `zÃÇ‚ÜíxÃÇ`.\n",
    "    projection: nn.Module\n",
    "        MODULE: Responsible for projecting `zÃÇ‚ÜíxÃÇ`.\n",
    "    filter: nn.Module\n",
    "        MODULE: Responsible for updating `(xÃÇ, x_obs) ‚ÜíxÃÇ'`.\n",
    "    \"\"\"\n",
    "\n",
    "    name: Final[str] = __name__\n",
    "    \"\"\"str: The name of the model.\"\"\"\n",
    "\n",
    "    HP = {\n",
    "        \"__name__\": __qualname__,  # type: ignore[name-defined]\n",
    "        \"__doc__\": __doc__,\n",
    "        \"__module__\": __module__,  # type: ignore[name-defined]\n",
    "        \"input_size\": int,\n",
    "        \"hidden_size\": int,\n",
    "        \"output_size\": int,\n",
    "        \"System\": LinODECell.HP,\n",
    "        \"Embedding\": ConcatEmbedding.HP,\n",
    "        \"Projection\": ConcatProjection.HP,\n",
    "        \"Filter\": RecurrentCellFilter.HP | {\"autoregressive\": True},\n",
    "        \"Encoder\": iResNet.HP,\n",
    "        \"Decoder\": iResNet.HP,\n",
    "    }\n",
    "    r\"\"\"Dictionary of Hyperparameters.\"\"\"\n",
    "\n",
    "    # Constants\n",
    "    input_size: Final[int]\n",
    "    r\"\"\"CONST: The dimensionality of the inputs.\"\"\"\n",
    "    hidden_size: Final[int]\n",
    "    r\"\"\"CONST: The dimensionality of the linear ODE.\"\"\"\n",
    "    output_size: Final[int]\n",
    "    r\"\"\"CONST: The dimensionality of the outputs.\"\"\"\n",
    "\n",
    "    # Buffers\n",
    "    zero: Tensor\n",
    "    r\"\"\"BUFFER: A tensor of value float(0.0)\"\"\"\n",
    "    xhat_pre: Tensor\n",
    "    r\"\"\"BUFFER: Stores pre-jump values.\"\"\"\n",
    "    xhat_post: Tensor\n",
    "    r\"\"\"BUFFER: Stores post-jump values.\"\"\"\n",
    "    zhat_pre: Tensor\n",
    "    r\"\"\"BUFFER: Stores pre-jump latent values.\"\"\"\n",
    "    zhat_post: Tensor\n",
    "    r\"\"\"BUFFER: Stores post-jump latent values.\"\"\"\n",
    "    timedeltas: Tensor\n",
    "    \"\"\"BUFFER: Stores the timedelta values.\"\"\"\n",
    "\n",
    "    # Parameters:\n",
    "    kernel: Tensor\n",
    "    r\"\"\"PARAM: The system matrix of the linear ODE component.\"\"\"\n",
    "    z0: Tensor\n",
    "    r\"\"\"PARAM: The initial latent state.\"\"\"\n",
    "\n",
    "    # Sub-Modules\n",
    "    # encoder: Any\n",
    "    # r\"\"\"MODULE: Responsible for embedding `xÃÇ‚ÜízÃÇ`.\"\"\"\n",
    "    # embedding: nn.Module\n",
    "    # r\"\"\"MODULE: Responsible for embedding `xÃÇ‚ÜízÃÇ`.\"\"\"\n",
    "    # system: nn.Module\n",
    "    # r\"\"\"MODULE: Responsible for propagating `zÃÇ_t‚ÜízÃÇ_{t+‚àÜt}`.\"\"\"\n",
    "    # decoder: nn.Module\n",
    "    # r\"\"\"MODULE: Responsible for projecting `zÃÇ‚ÜíxÃÇ`.\"\"\"\n",
    "    # projection: nn.Module\n",
    "    # r\"\"\"MODULE: Responsible for projecting `zÃÇ‚ÜíxÃÇ`.\"\"\"\n",
    "    # filter: nn.Module\n",
    "    # r\"\"\"MODULE: Responsible for updating `(xÃÇ, x_obs) ‚ÜíxÃÇ'`.\"\"\"\n",
    "\n",
    "    def __init__(self, input_size: int, hidden_size: int, **HP: Any):\n",
    "        super().__init__()\n",
    "        self.CFG = HP = deep_dict_update(self.HP, HP)\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = input_size\n",
    "\n",
    "        HP[\"Encoder\"][\"input_size\"] = hidden_size\n",
    "        HP[\"Decoder\"][\"input_size\"] = hidden_size\n",
    "        HP[\"System\"][\"input_size\"] = hidden_size\n",
    "        HP[\"Filter\"][\"hidden_size\"] = input_size\n",
    "        HP[\"Filter\"][\"input_size\"] = input_size\n",
    "        HP[\"Embedding\"][\"input_size\"] = input_size\n",
    "        HP[\"Embedding\"][\"hidden_size\"] = hidden_size\n",
    "        HP[\"Projection\"][\"input_size\"] = input_size\n",
    "        HP[\"Projection\"][\"hidden_size\"] = hidden_size\n",
    "\n",
    "        # if HP[\"embedding_type\"] == \"linear\":\n",
    "        #     _embedding: nn.Module = nn.Linear(input_size, hidden_size)\n",
    "        #     _projection: nn.Module = nn.Linear(hidden_size, input_size)\n",
    "        # elif HP[\"embedding_type\"] == \"concat\":\n",
    "        #     _embedding = ConcatEmbedding(input_size, hidden_size)\n",
    "        #     _projection = ConcatProjection(input_size, hidden_size)\n",
    "        # else:\n",
    "        #     raise NotImplementedError(\n",
    "        #         f\"{HP['embedding_type']=}\" + \"not in {'linear', 'concat'}\"\n",
    "        #     )\n",
    "\n",
    "        # TODO: replace with add_module once supported!\n",
    "        # self.add_module(\"embedding\", _embedding)\n",
    "        # self.add_module(\"encoder\", HP[\"Encoder\"](**HP[\"Encoder_cfg\"]))\n",
    "        # self.add_module(\"system\", HP[\"System\"](**HP[\"System_cfg\"]))\n",
    "        # self.add_module(\"decoder\", HP[\"Decoder\"](**HP[\"Decoder_cfg\"]))\n",
    "        # self.add_module(\"projection\", _projection)\n",
    "        # self.add_module(\"filter\", HP[\"Filter\"](**HP[\"Filter_cfg\"]))\n",
    "        __logger__.debug(\"%s Initializing Embedding %s\", self.name, HP[\"Embedding\"])\n",
    "        self.embedding: nn.Module = initialize_from_config(HP[\"Embedding\"])\n",
    "        __logger__.debug(\"%s Initializing Embedding %s\", self.name, HP[\"Embedding\"])\n",
    "        self.projection: nn.Module = initialize_from_config(HP[\"Projection\"])\n",
    "        __logger__.debug(\"%s Initializing Encoder %s\", self.name, HP[\"Encoder\"])\n",
    "        self.encoder: nn.Module = initialize_from_config(HP[\"Encoder\"])\n",
    "        __logger__.debug(\"%s Initializing System %s\", self.name, HP[\"Encoder\"])\n",
    "        self.system: nn.Module = initialize_from_config(HP[\"System\"])\n",
    "        __logger__.debug(\"%s Initializing Decoder %s\", self.name, HP[\"Encoder\"])\n",
    "        self.decoder: nn.Module = initialize_from_config(HP[\"Decoder\"])\n",
    "        __logger__.debug(\"%s Initializing Filter %s\", self.name, HP[\"Encoder\"])\n",
    "        self.filter: Filter = initialize_from_config(HP[\"Filter\"])\n",
    "\n",
    "        assert isinstance(self.system.kernel, Tensor)\n",
    "        self.kernel = self.system.kernel\n",
    "        self.z0 = nn.Parameter(torch.randn(self.hidden_size))\n",
    "\n",
    "        # Buffers\n",
    "        self.register_buffer(\"zero\", torch.tensor(0.0), persistent=False)\n",
    "        self.register_buffer(\"timedeltas\", torch.tensor(()), persistent=False)\n",
    "        self.register_buffer(\"xhat_pre\", torch.tensor(()), persistent=False)\n",
    "        self.register_buffer(\"xhat_post\", torch.tensor(()), persistent=False)\n",
    "        self.register_buffer(\"zhat_pre\", torch.tensor(()), persistent=False)\n",
    "        self.register_buffer(\"zhat_post\", torch.tensor(()), persistent=False)\n",
    "\n",
    "    @jit.export\n",
    "    def forward(self, T: Tensor, X: Tensor) -> Tensor:\n",
    "        r\"\"\"Signature: `[...,N]√ó[...,N,d] ‚ü∂ [...,N,d]`.\n",
    "\n",
    "        **Model Sketch**::\n",
    "\n",
    "            ‚ü∂ [ODE] ‚ü∂ (zÃÇ·µ¢)                (zÃÇ·µ¢') ‚ü∂ [ODE] ‚ü∂\n",
    "                       ‚Üì                   ‚Üë\n",
    "                      [Œ®]                 [Œ¶]\n",
    "                       ‚Üì                   ‚Üë\n",
    "                      (xÃÇ·µ¢) ‚Üí [ filter ] ‚Üí (xÃÇ·µ¢')\n",
    "                                 ‚Üë\n",
    "                              (t·µ¢, x·µ¢)\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        T: Tensor, shape=(...,LEN) or PackedSequence\n",
    "            The timestamps of the observations.\n",
    "        X: Tensor, shape=(...,LEN,DIM) or PackedSequence\n",
    "            The observed, noisy values at times `t‚ààT`. Use ``NaN`` to indicate missing values.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        XÃÇ_pre: Tensor, shape=(...,LEN,DIM)\n",
    "            The estimated true state of the system at the times `t‚Åª‚ààT` (pre-update).\n",
    "        XÃÇ_post: Tensor, shape=(...,LEN,DIM)\n",
    "            The estimated true state of the system at the times `t‚Å∫‚ààT` (post-update).\n",
    "\n",
    "        References\n",
    "        ----------\n",
    "        - https://pytorch.org/blog/optimizing-cuda-rnn-with-torchscript/\n",
    "        \"\"\"\n",
    "        BATCH_SIZE = X.shape[:-2]\n",
    "        # prepend a single zero for the first iteration.\n",
    "        pad_dim = list(BATCH_SIZE) + [1]\n",
    "        pad = torch.zeros(pad_dim, device=T.device, dtype=T.dtype)\n",
    "        DT = torch.diff(T, prepend=pad, dim=-1)  # (..., LEN) ‚Üí (..., LEN)\n",
    "        DT = DT.moveaxis(-1, 0)  # (..., LEN) ‚Üí (LEN, ...)\n",
    "        X = torch.moveaxis(X, -2, 0)  # (...,LEN,DIM) ‚Üí (LEN,...,DIM)\n",
    "\n",
    "        Zhat_pre: list[Tensor] = []\n",
    "        Xhat_pre: list[Tensor] = []\n",
    "        Xhat_post: list[Tensor] = []\n",
    "        Zhat_post: list[Tensor] = []\n",
    "\n",
    "        zÃÇ_post = self.z0\n",
    "\n",
    "        for dt, x_obs in zip(DT, X):\n",
    "            # Propagate the latent state forward in time.\n",
    "            zÃÇ_pre = self.system(dt, zÃÇ_post)  # (...,), (...,LAT) -> (...,LAT)\n",
    "\n",
    "            # Decode the latent state at the observation time.\n",
    "            xÃÇ_pre = self.projection(self.decoder(zÃÇ_pre))  # (...,LAT) -> (...,DIM)\n",
    "\n",
    "            # Update the state estimate by filtering the observation.\n",
    "            xÃÇ_post = self.filter(x_obs, xÃÇ_pre)  # (...,DIM), (..., DIM) ‚Üí (...,DIM)\n",
    "\n",
    "            # Encode the latent state at the observation time.\n",
    "            zÃÇ_post = self.encoder(self.embedding(xÃÇ_post))  # (...,DIM) ‚Üí (...,LAT)\n",
    "\n",
    "            # Save all tensors for later.\n",
    "            Zhat_pre.append(zÃÇ_pre)\n",
    "            Xhat_pre.append(xÃÇ_pre)\n",
    "            Xhat_post.append(xÃÇ_post)\n",
    "            Zhat_post.append(zÃÇ_post)\n",
    "\n",
    "        self.xhat_pre = torch.stack(Xhat_pre, dim=-2)\n",
    "        self.xhat_post = torch.stack(Xhat_post, dim=-2)\n",
    "        self.zhat_pre = torch.stack(Zhat_pre, dim=-2)\n",
    "        self.zhat_post = torch.stack(Zhat_post, dim=-2)\n",
    "        self.timedeltas = DT.moveaxis(0, -1)\n",
    "\n",
    "        return self.xhat_post\n",
    "\n",
    "        # TODO: Control variables\n",
    "        # xhat = self.control(xhat, u)\n",
    "        # u: possible controls:\n",
    "        #  1. set to value\n",
    "        #  2. add to value\n",
    "        # do these via indicator variable\n",
    "        # u = (time, value, mode-indicator, col-indicator)\n",
    "        # => apply control to specific column.\n",
    "\n",
    "        # TODO: Smarter initialization\n",
    "        # IDEA: The problem is the initial state of RNNCell is not defined and typically put equal\n",
    "        # to zero. Staying with the idea that the Cell acts as a filter, that is updates the state\n",
    "        # estimation given an observation, we could \"trust\" the original observation in the sense\n",
    "        # that we solve the fixed point equation h0 = g(x0, h0) and put the solution as the initial\n",
    "        # state.\n",
    "        # issue: if x0 is really sparse this is useless.\n",
    "        # better idea: we probably should go back and forth.\n",
    "        # other idea: use a set-based model and put h = g(T,X), including the whole TS.\n",
    "        # This set model can use triplet notation.\n",
    "        # bias weighting towards close time points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de358424-917f-4f7a-bf25-c857442dfb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(LinODEnet(2, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb71bda5-5099-4af9-a6d9-9f13a339d5e2",
   "metadata": {},
   "source": [
    "## LinODEnet v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fff4a4-c09c-4610-9351-156589435392",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from typing import Any, Final, overload\n",
    "\n",
    "import torch\n",
    "from linodenet.initializations.functional import FunctionalInitialization\n",
    "from linodenet.models.embeddings import ConcatEmbedding, ConcatProjection\n",
    "from linodenet.models.encoders import iResNet\n",
    "from linodenet.models.filters import Filter, RecurrentCellFilter\n",
    "from linodenet.models.system import LinODECell\n",
    "from linodenet.projections import Projection\n",
    "from linodenet.util import autojit, deep_dict_update, initialize_from_config\n",
    "from torch import Tensor, jit, nn\n",
    "\n",
    "__logger__ = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "# @autojit\n",
    "class LinODEnet(nn.Module):\n",
    "    HP = {\n",
    "        \"__name__\": __qualname__,  # type: ignore[name-defined]\n",
    "        \"__doc__\": __doc__,\n",
    "        \"__module__\": __module__,  # type: ignore[name-defined]\n",
    "        \"input_size\": int,\n",
    "        \"hidden_size\": int,\n",
    "        \"output_size\": int,\n",
    "        \"System\": LinODECell.HP,\n",
    "        \"Embedding\": ConcatEmbedding.HP,\n",
    "        \"Projection\": ConcatProjection.HP,\n",
    "        \"Filter\": RecurrentCellFilter.HP | {\"autoregressive\": True},\n",
    "        \"Encoder\": iResNet.HP,\n",
    "        \"Decoder\": iResNet.HP,\n",
    "    }\n",
    "    r\"\"\"Dictionary of Hyperparameters.\"\"\"\n",
    "\n",
    "    # Constants\n",
    "    input_size: Final[int]\n",
    "    r\"\"\"CONST: The dimensionality of the inputs.\"\"\"\n",
    "    hidden_size: Final[int]\n",
    "    r\"\"\"CONST: The dimensionality of the linear ODE.\"\"\"\n",
    "    output_size: Final[int]\n",
    "    r\"\"\"CONST: The dimensionality of the outputs.\"\"\"\n",
    "\n",
    "    # Buffers\n",
    "    zero: Tensor\n",
    "    r\"\"\"BUFFER: A tensor of value float(0.0)\"\"\"\n",
    "    xhat_pre: Tensor\n",
    "    r\"\"\"BUFFER: Stores pre-jump values.\"\"\"\n",
    "    xhat_post: Tensor\n",
    "    r\"\"\"BUFFER: Stores post-jump values.\"\"\"\n",
    "    zhat_pre: Tensor\n",
    "    r\"\"\"BUFFER: Stores pre-jump latent values.\"\"\"\n",
    "    zhat_post: Tensor\n",
    "    r\"\"\"BUFFER: Stores post-jump latent values.\"\"\"\n",
    "    timedeltas: Tensor\n",
    "    \"\"\"BUFFER: Stores the timedelta values.\"\"\"\n",
    "\n",
    "    # Parameters:\n",
    "    kernel: Tensor\n",
    "    r\"\"\"PARAM: The system matrix of the linear ODE component.\"\"\"\n",
    "    z0: Tensor\n",
    "    r\"\"\"PARAM: The initial latent state.\"\"\"\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(\n",
    "        cls,\n",
    "        *,\n",
    "        input_size: int,\n",
    "        hidden_size: int,\n",
    "        output_size: int,\n",
    "        System: LinODECell.HP,\n",
    "        Embedding: ConcatEmbedding.HP,\n",
    "        Projection: ConcatProjection.HP,\n",
    "        Filter: RecurrentCellFilter.HP | {\"autoregressive\": True},\n",
    "        Encoder: iResNet.HP,\n",
    "        Decoder: iResNet.HP,\n",
    "    ):\n",
    "        ...\n",
    "\n",
    "    def __new__(cls, *args, **kwargs):\n",
    "        ...\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        System: nn.Module,\n",
    "        Filter: nn.Module,\n",
    "        Encoder: nn.Module,\n",
    "        Embedding: nn.Module,\n",
    "        Decoder: Optional[nn.Module] = None,\n",
    "        Projection: Optional[nn.Module] = None,\n",
    "    ):\n",
    "        \"\"\"If Projection is None, will assume to use Embedding.inverse.\"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # Register Modules\n",
    "        self.register_module(\"embedding\", Embedding)\n",
    "        self.register_module(\"projection\", Projection)\n",
    "        self.register_module(\"encoder\", Encoder)\n",
    "        self.register_module(\"system\", System)\n",
    "        self.register_module(\"decoder\", Decoder)\n",
    "        self.register_module(\"filter\", Filter)\n",
    "\n",
    "        # Register Buffers\n",
    "        self.register_buffer(\"zero\", torch.tensor(0.0), persistent=False)\n",
    "        self.register_buffer(\"timedeltas\", torch.tensor(()), persistent=False)\n",
    "        self.register_buffer(\"xhat_pre\", torch.tensor(()), persistent=False)\n",
    "        self.register_buffer(\"xhat_post\", torch.tensor(()), persistent=False)\n",
    "        self.register_buffer(\"zhat_pre\", torch.tensor(()), persistent=False)\n",
    "        self.register_buffer(\"zhat_post\", torch.tensor(()), persistent=False)\n",
    "\n",
    "        # Register Parameters\n",
    "        self.register_parameter(\"z0\", nn.Parameter(torch.randn(self.hidden_size)))\n",
    "\n",
    "        # self.register_parameter(\"kernel\", self.system.k)\n",
    "        # assert isinstance(self.system.kernel, Tensor)\n",
    "        # self.kernel = self.system.kernel\n",
    "        # self.z0 = nn.Parameter(torch.randn(self.hidden_size))\n",
    "\n",
    "    def __init__(self, input_size: int, hidden_size: int, **HP: Any):\n",
    "        super().__init__()\n",
    "        self.CFG = HP = deep_dict_update(self.HP, HP)\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = input_size\n",
    "\n",
    "        HP[\"Encoder\"][\"input_size\"] = hidden_size\n",
    "        HP[\"Decoder\"][\"input_size\"] = hidden_size\n",
    "        HP[\"System\"][\"input_size\"] = hidden_size\n",
    "        HP[\"Filter\"][\"hidden_size\"] = input_size\n",
    "        HP[\"Filter\"][\"input_size\"] = input_size\n",
    "        HP[\"Embedding\"][\"input_size\"] = input_size\n",
    "        HP[\"Embedding\"][\"hidden_size\"] = hidden_size\n",
    "        HP[\"Projection\"][\"input_size\"] = input_size\n",
    "        HP[\"Projection\"][\"hidden_size\"] = hidden_size\n",
    "\n",
    "    @jit.export\n",
    "    def forward(self, T: Tensor, X: Tensor) -> Tensor:\n",
    "        BATCH_SIZE = X.shape[:-2]\n",
    "        # prepend a single zero for the first iteration.\n",
    "        pad_dim = list(BATCH_SIZE) + [1]\n",
    "        pad = torch.zeros(pad_dim, device=T.device, dtype=T.dtype)\n",
    "        DT = torch.diff(T, prepend=pad, dim=-1)  # (..., LEN) ‚Üí (..., LEN)\n",
    "        DT = DT.moveaxis(-1, 0)  # (..., LEN) ‚Üí (LEN, ...)\n",
    "        X = torch.moveaxis(X, -2, 0)  # (...,LEN,DIM) ‚Üí (LEN,...,DIM)\n",
    "\n",
    "        Zhat_pre: list[Tensor] = []\n",
    "        Xhat_pre: list[Tensor] = []\n",
    "        Xhat_post: list[Tensor] = []\n",
    "        Zhat_post: list[Tensor] = []\n",
    "\n",
    "        zÃÇ_post = self.z0\n",
    "\n",
    "        for dt, x_obs in zip(DT, X):\n",
    "            # Propagate the latent state forward in time.\n",
    "            zÃÇ_pre = self.system(dt, zÃÇ_post)  # (...,), (...,LAT) -> (...,LAT)\n",
    "\n",
    "            # Decode the latent state at the observation time.\n",
    "            xÃÇ_pre = self.projection(self.decoder(zÃÇ_pre))  # (...,LAT) -> (...,DIM)\n",
    "\n",
    "            # Update the state estimate by filtering the observation.\n",
    "            xÃÇ_post = self.filter(x_obs, xÃÇ_pre)  # (...,DIM), (..., DIM) ‚Üí (...,DIM)\n",
    "\n",
    "            # Encode the latent state at the observation time.\n",
    "            zÃÇ_post = self.encoder(self.embedding(xÃÇ_post))  # (...,DIM) ‚Üí (...,LAT)\n",
    "\n",
    "            # Save all tensors for later.\n",
    "            Zhat_pre.append(zÃÇ_pre)\n",
    "            Xhat_pre.append(xÃÇ_pre)\n",
    "            Xhat_post.append(xÃÇ_post)\n",
    "            Zhat_post.append(zÃÇ_post)\n",
    "\n",
    "        self.xhat_pre = torch.stack(Xhat_pre, dim=-2)\n",
    "        self.xhat_post = torch.stack(Xhat_post, dim=-2)\n",
    "        self.zhat_pre = torch.stack(Zhat_pre, dim=-2)\n",
    "        self.zhat_post = torch.stack(Zhat_post, dim=-2)\n",
    "        self.timedeltas = DT.moveaxis(0, -1)\n",
    "\n",
    "        return self.xhat_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178a3846-aa06-4d9f-9a45-81831896cb99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d695b42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Final, Optional\n",
    "\n",
    "import torch\n",
    "from torch import Tensor, jit, nn\n",
    "\n",
    "\n",
    "# @autojit\n",
    "class ConcatProjection(nn.Module):\n",
    "    r\"\"\"Maps `z = [x,w] ‚üº x`.\"\"\"\n",
    "\n",
    "    # Constants\n",
    "    input_size: Final[int]\n",
    "    r\"\"\"CONST: The dimensionality of the inputs.\"\"\"\n",
    "    hidden_size: Final[int]\n",
    "    r\"\"\"CONST: The dimensionality of the outputs.\"\"\"\n",
    "    pad_size: Final[int]\n",
    "    r\"\"\"CONST: The size of the padding.\"\"\"\n",
    "\n",
    "    # Parameters\n",
    "    padding: Tensor\n",
    "    r\"\"\"PARAM: The padding vector.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size: int,\n",
    "        hidden_size: int,\n",
    "        padding: Optional[Tensor] = None,\n",
    "        # inverted: Optional[nn.Module] = None,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        if not input_size >= hidden_size:\n",
    "            raise ValueError(\n",
    "                f\"ConcatProjection requires {input_size=} ‚â• {hidden_size=}!\"\n",
    "            )\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.pad_size = input_size - hidden_size\n",
    "\n",
    "        if padding is None:\n",
    "            padding = nn.Parameter(torch.randn(self.pad_size))\n",
    "        elif not isinstance(padding, nn.Parameter):\n",
    "            padding = nn.Parameter(padding)\n",
    "\n",
    "        self.register_parameter(\"padding\", padding)\n",
    "\n",
    "    #         if inverted is None:\n",
    "    #             inverted = ConcatEmbedding(\n",
    "    #                 input_size=self.hidden_size,\n",
    "    #                 hidden_size=self.input_size,\n",
    "    #                 padding=self.padding,\n",
    "    #                 inverted=self,\n",
    "    #             )\n",
    "    #         self.inverted = inverted\n",
    "\n",
    "    @property\n",
    "    def inverted(self):\n",
    "        return ConcatEmbedding(\n",
    "            input_size=self.hidden_size,\n",
    "            hidden_size=self.input_size,\n",
    "            padding=self.padding,\n",
    "        )\n",
    "\n",
    "    @jit.export\n",
    "    def __invert__(self):\n",
    "        return self.inverted\n",
    "\n",
    "    @jit.export\n",
    "    def forward(self, Z: Tensor) -> Tensor:\n",
    "        r\"\"\"Signature: `[..., d+e] ‚ü∂ [..., d]`.\"\"\"\n",
    "        return Z[..., : self.hidden_size]\n",
    "\n",
    "    @jit.export\n",
    "    def inverse(self, X: Tensor) -> Tensor:\n",
    "        r\"\"\"Signature: `[..., d] ‚ü∂ [..., d+e]`.\"\"\"\n",
    "        shape = list(X.shape[:-1]) + [self.pad_size]\n",
    "        return torch.cat([X, self.padding.expand(shape)], dim=-1)\n",
    "\n",
    "\n",
    "# @autojit\n",
    "class ConcatEmbedding(nn.Module):\n",
    "    r\"\"\"Maps `x ‚üº [x,w]`.\"\"\"\n",
    "\n",
    "    # Constants|\n",
    "    input_size: Final[int]\n",
    "    r\"\"\"CONST: The dimensionality of the inputs.\"\"\"\n",
    "    hidden_size: Final[int]\n",
    "    r\"\"\"CONST: The dimensionality of the outputs.\"\"\"\n",
    "    pad_size: Final[int]\n",
    "    r\"\"\"CONST: The size of the padding.\"\"\"\n",
    "\n",
    "    # Parameters\n",
    "    padding: Tensor\n",
    "    r\"\"\"PARAM: The padding vector.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        input_size: int,\n",
    "        hidden_size: int,\n",
    "        padding: Optional[Tensor] = None,\n",
    "        # inverted: Optional[nn.Module] = None,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        if not input_size <= hidden_size:\n",
    "            raise ValueError(\n",
    "                f\"ConcatEmbedding requires {input_size=} ‚â§ {hidden_size=}!\"\n",
    "            )\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.pad_size = hidden_size - input_size\n",
    "\n",
    "        padding = None\n",
    "        if padding is None:\n",
    "            padding = nn.Parameter(torch.randn(self.pad_size))\n",
    "        elif not isinstance(padding, nn.Parameter):\n",
    "            padding = nn.Parameter(padding)\n",
    "\n",
    "        self.register_parameter(\"padding\", padding)\n",
    "\n",
    "        # if inverted is None:\n",
    "        #     inverted = ConcatProjection(\n",
    "        #         input_size=self.hidden_size,\n",
    "        #         hidden_size=self.input_size,\n",
    "        #         padding=self.padding,\n",
    "        #         inverted=self,\n",
    "        #     )\n",
    "        # self.inverted = inverted\n",
    "\n",
    "    @property\n",
    "    def inverted(self):\n",
    "        return ConcatProjection(\n",
    "            input_size=self.hidden_size,\n",
    "            hidden_size=self.input_size,\n",
    "            padding=self.padding,\n",
    "        )\n",
    "\n",
    "    @jit.export\n",
    "    def __invert__(self):\n",
    "        return self.inverted\n",
    "\n",
    "    @jit.export\n",
    "    def forward(self, X: Tensor) -> Tensor:\n",
    "        r\"\"\"Signature: `[..., d] ‚ü∂ [..., d+e]`.\"\"\"\n",
    "        shape = list(X.shape[:-1]) + [self.pad_size]\n",
    "        return torch.cat([X, self.padding.expand(shape)], dim=-1)\n",
    "\n",
    "    @jit.export\n",
    "    def inverse(self, Z: Tensor) -> Tensor:\n",
    "        r\"\"\"Signature: `[..., d+e] ‚ü∂ [..., d]`.\"\"\"\n",
    "        return Z[..., : self.input_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0476b0-e60d-40f4-b772-e57638d73988",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConcatEmbedding(input_size=4, hidden_size=16)\n",
    "# assert model is ~(~model)\n",
    "\n",
    "model = ConcatProjection(input_size=16, hidden_size=4)\n",
    "# assert model is ~(~model)\n",
    "\n",
    "print(model)\n",
    "jit.script(model)  # RecursionError: maximum recursion depth exceeded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9007aa07-fff8-418d-8131-d33d7d4b0fd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968cbd08-dc2c-4adb-bc40-9e39db848e69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ade2893-b091-4375-9d46-b1ebeee813e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "jit.script(model);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e3f31d-5e50-4ccf-ae0f-063762aee3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model(torch.randn(8, 4))\n",
    "model.inverse(torch.randn(3, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99605267-7ddd-49d9-8d66-fe0f0e4b07e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted = model.invert()\n",
    "original = inverted.invert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0184e3b-c476-4a2b-83b7-ba6a1fecc457",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConcatProjection(16, 4)\n",
    "\n",
    "model.inverse(torch.randn(8, 4))\n",
    "model.forward(torch.randn(3, 16))\n",
    "# model.inverse(torch.randn(8, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c95efe-ebbf-4ee4-91ae-5486a596e6c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080b1e60-6d15-4eb2-9fc7-ca7dea754871",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
