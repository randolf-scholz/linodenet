{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InteractiveShell.ast_node_interactivity='last_expr_or_assign'  # always print last expr.\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import jit, Tensor, nn\n",
    "from torch.nn import Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from linodenet.models import LinearContraction\n",
    "\n",
    "model = LinearContraction(3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.jit.RecursiveScriptModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "issubclass(torch.jit.RecursiveScriptModule, nn.Module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.set_printoptions(precision=4, floatmode=\"fixed\", suppress=True)\n",
    "rng = np.random.default_rng()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import jit, Tensor, nn\n",
    "from torch.nn import Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "r\"\"\"Module Docstring.\"\"\"\n",
    "\n",
    "\n",
    "from functools import wraps\n",
    "\n",
    "\n",
    "def wrapfunc(other):\n",
    "    def autodeco(func):\n",
    "        @wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            return other(func(*args, **kwargs))\n",
    "\n",
    "        return wrapper\n",
    "\n",
    "    return autodeco\n",
    "\n",
    "\n",
    "def autojit_a(basecls: type[Module]) -> type[Module]:\n",
    "\n",
    "    assert issubclass(basecls, Module)\n",
    "\n",
    "    @wraps(basecls, updated=())\n",
    "    class WrappedClass(basecls):\n",
    "        def __new__(cls, *args, **kwargs):\n",
    "            instance = basecls()\n",
    "            return jit.script(instance)\n",
    "\n",
    "    return WrappedClass\n",
    "\n",
    "\n",
    "def autojit_b(basecls: type[Module]) -> type[Module]:\n",
    "\n",
    "    assert issubclass(basecls, Module)\n",
    "\n",
    "    @wraps(Module, updated=())\n",
    "    class WrappedClass(Module):\n",
    "        def __new__(cls, *args, **kwargs):\n",
    "            instance = basecls()\n",
    "            return jit.script(instance)\n",
    "\n",
    "    return WrappedClass\n",
    "\n",
    "\n",
    "def autojit_c(basecls: type[Module]) -> type[Module]:\n",
    "\n",
    "    assert issubclass(basecls, Module)\n",
    "\n",
    "    basecls.__new__ = wrapfunc(jit.script)(basecls.__new__)\n",
    "\n",
    "    return basecls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModule(Module):\n",
    "    a: Tensor\n",
    "\n",
    "    def __init__(self, a: float = 1.0):\n",
    "        super().__init__()\n",
    "        self.a = torch.tensor(a)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self.a * x\n",
    "\n",
    "\n",
    "MyModule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "@autojit_a\n",
    "class MyModule(Module):\n",
    "    a: Tensor\n",
    "\n",
    "    def __init__(self, a: float = 1.0):\n",
    "        super().__init__()\n",
    "        self.a = torch.tensor(a)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self.a * x\n",
    "\n",
    "\n",
    "MyModule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "@autojit_b\n",
    "class MyModule(Module):\n",
    "    a: Tensor\n",
    "\n",
    "    def __init__(self, a: float = 1.0):\n",
    "        super().__init__()\n",
    "        self.a = torch.tensor(a)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self.a * x\n",
    "\n",
    "\n",
    "MyModule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "@autojit_c\n",
    "class MyModule(Module):\n",
    "    a: Tensor\n",
    "\n",
    "    def __init__(self, a: float = 1.0):\n",
    "        super().__init__()\n",
    "        self.a = torch.tensor(a)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self.a * x\n",
    "\n",
    "\n",
    "MyModule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
