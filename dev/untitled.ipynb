{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20191951-beec-414a-b3c6-89dca8277ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InteractiveShell.ast_node_interactivity='last_expr_or_assign'  # always print last expr.\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torch.export import export, Dim"
   ],
   "metadata": {},
   "id": "6fe78b73ceee6905",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {},
   "id": "e466620b611c275b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from collections.abc import Mapping\n",
    "\n",
    "import torch\n",
    "from torch import Tensor, jit, nn\n",
    "from typing_extensions import Any, Final, Optional, Self"
   ],
   "metadata": {},
   "id": "dcb5790eaf23f1b2",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class ReZeroCell(nn.Module):\n",
    "    r\"\"\"ReZero module.\n",
    "\n",
    "    Simply multiplies the inputs by a scalar initialized to zero.\n",
    "    \"\"\"\n",
    "\n",
    "    HP = {\n",
    "        \"__name__\": __qualname__,\n",
    "        \"__module__\": __name__,\n",
    "    }\n",
    "    r\"\"\"The hyperparameter dictionary\"\"\"\n",
    "\n",
    "    # CONSTANTS\n",
    "    learnable: Final[bool]\n",
    "    r\"\"\"CONST: Whether the scalar is learnable.\"\"\"\n",
    "\n",
    "    # PARAMETERS\n",
    "    scalar: Tensor\n",
    "    r\"\"\"The scalar to multiply the inputs by.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        module: Optional[nn.Module] = None,\n",
    "        *,\n",
    "        scalar: Optional[Tensor] = None,\n",
    "        learnable: bool = True,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.learnable = bool(learnable)\n",
    "        self.module = module\n",
    "        initial_value = torch.as_tensor(0.0 if scalar is None else scalar)\n",
    "        self.scalar = nn.Parameter(initial_value) if self.learnable else initial_value\n",
    "\n",
    "\n",
    "    @jit.export\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\".. Signature:: ``(...,) -> (...,)``.\"\"\"\n",
    "        if self.module is None:\n",
    "            return self.scalar * x\n",
    "        return self.scalar * self.module(x)\n"
   ],
   "metadata": {},
   "id": "11881e93d97f0f62",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "mod = ReZeroCell(nn.Linear(3,3))\n",
    "m = jit.script(mod)"
   ],
   "metadata": {},
   "id": "75bb6392d558c225",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "m.graph"
   ],
   "metadata": {},
   "id": "e3e489e466d3072a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {},
   "id": "595df3d68ab0e913"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "aamodel = torch.compile(mod, dynamic=True)"
   ],
   "metadata": {},
   "id": "1170a6b577e63fa4",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {},
   "id": "ad42ad779cfc701b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model(torch.randn(1))"
   ],
   "metadata": {},
   "id": "23d8695a9465fa78",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "x = torch.randn(7,2)\n",
    "args = (x,)\n",
    "shapes = {\"x\" : {0: Dim(\"batch\"), 1: Dim(\"feature\")}}\n",
    "exported_mod = export(mod, args, dynamic_shapes=shapes)"
   ],
   "metadata": {},
   "id": "d0499d6afa24a6ff",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "exported_mod(torch.randn(4))"
   ],
   "metadata": {},
   "id": "e94ad2338dd1eb6f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.export import Dim, export\n",
    "\n",
    "class M(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.branch1 = torch.nn.Sequential(\n",
    "            torch.nn.Linear(64, 32), torch.nn.ReLU()\n",
    "        )\n",
    "        self.branch2 = torch.nn.Sequential(\n",
    "            torch.nn.Linear(128, 64), torch.nn.ReLU()\n",
    "        )\n",
    "        self.buffer = torch.ones(32)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        out1 = self.branch1(x1)\n",
    "        out2 = self.branch2(x2)\n",
    "        return (out1 + self.buffer, out2)\n",
    "\n",
    "example_args = (torch.randn(32, 64), torch.randn(32, 128))\n",
    "\n",
    "# Create a dynamic batch size\n",
    "batch = Dim(\"batch\")\n",
    "# Specify that the first dimension of each input is that batch size\n",
    "dynamic_shapes = {\"x1\": {0: batch}, \"x2\": {0: batch}}\n",
    "\n",
    "exported_program: torch.export.ExportedProgram = export(\n",
    "    M(), args=example_args, dynamic_shapes=dynamic_shapes\n",
    ")\n",
    "print(exported_program)"
   ],
   "metadata": {},
   "id": "46c2c80dbd98a09a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "aclass ReZero(nn.ModuleList):\n",
    "    r\"\"\"A ReZero model.\"\"\"\n",
    "\n",
    "    def __init__(self, blocks: nn.Module, weights: Optional[Tensor] = None) -> None:\n",
    "        super().__init__(blocks)\n",
    "\n",
    "        self.weights = nn.Parameter(\n",
    "            torch.zeros(len(blocks)) if weights is None else weights\n",
    "        )\n",
    "        # self.blocks = nn.ModuleList(blocks)\n",
    "        # super().__init__(blocks)\n",
    "\n",
    "    @jit.export\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        for k, block in enumerate(self):\n",
    "            x = x + self.weights[k] * block(x)\n",
    "        return x"
   ],
   "metadata": {},
   "id": "35e0965351425f21",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "mod = ReZero([nn.Linear(3, 3), nn.Linear(3, 3), nn.Linear(3,3)])\n",
    "m = jit.script(mod)\n",
    "m"
   ],
   "metadata": {},
   "id": "632bbde910adf832",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "m(torch.randn(7, 3))"
   ],
   "metadata": {},
   "id": "22be2440d4a57415",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "m"
   ],
   "metadata": {},
   "id": "2cd68a7c693c808c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "m[:1].weights"
   ],
   "metadata": {},
   "id": "a00a08f6ea12dbcf",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {},
   "id": "d9ee7b80b63d9a05"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "aa\n",
    "class Constant(nn.Module):\n",
    "    r\"\"\"Constant function.\"\"\"\n",
    "\n",
    "    def __init__(self, value: float | Tensor) -> None:\n",
    "        super().__init__()\n",
    "        self.register_buffer(\"value\", torch.as_tensor(value))\n",
    "\n",
    "    def forward(self, _: Tensor) -> Tensor:\n",
    "        return self.value\n"
   ],
   "metadata": {},
   "id": "29c288dbaf9dfe38",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def foo(x: Tensor, y: Tensor) -> None:\n",
    "    \n",
    "    for x_, y_ in zip(x, y):\n",
    "        print(x_, y_)\n",
    "        print(x_ + y_)"
   ],
   "metadata": {},
   "id": "b0cfb65553b45f94",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "jit.script(foo)(torch.rand(3, 3), torch.rand(3, 3))"
   ],
   "metadata": {},
   "id": "8f9598d08f9ed63",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "jit.script(Constant(1.0))()"
   ],
   "metadata": {},
   "id": "e7084da499559e4d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b7f6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import metadata\n",
    "from typing import Any\n",
    "\n",
    "import torch\n",
    "import torchinfo\n",
    "\n",
    "from torch import jit\n",
    "from linodenet.models import LinODE, LinODECell, LinODEnet\n",
    "from linodenet.models.filters import SequentialFilter\n",
    "from linodenet.projections.functional import skew_symmetric, symmetric\n",
    "\n",
    "NUM_DIM = 128\n",
    "DEVICE = torch.device(\"cpu\")\n",
    "DTYPE = torch.float32\n",
    "\n",
    "\n",
    "def join_dicts(d: dict[str, Any]) -> dict[str, Any]:\n",
    "    \"\"\"Recursively join dict by composing keys with '/'.\"\"\"\n",
    "    result = {}\n",
    "    for key, val in d.items():\n",
    "        if isinstance(val, dict):\n",
    "            result |= join_dicts(\n",
    "                {f\"{key}/{subkey}\": item for subkey, item in val.items()}\n",
    "            )\n",
    "        else:\n",
    "            result[key] = val\n",
    "    return result\n",
    "\n",
    "\n",
    "def add_prefix(d: dict[str, Any], /, prefix: str) -> dict[str, Any]:\n",
    "    return {f\"{prefix}/{key}\": item for key, item in d.items()}\n",
    "\n",
    "\n",
    "# OPTIMIZER_CONIFG = {\n",
    "#     \"__name__\": \"SGD\",\n",
    "#     \"lr\": 0.001,\n",
    "#     \"momentum\": 0,\n",
    "#     \"dampening\": 0,\n",
    "#     \"weight_decay\": 0,\n",
    "#     \"nesterov\": False,\n",
    "# }\n",
    "\n",
    "# OPTIMIZER_CONFIG = {\n",
    "#     \"__name__\": \"Adam\",\n",
    "#     \"lr\": 0.01,\n",
    "#     \"betas\": (0.9, 0.999),\n",
    "#     \"eps\": 1e-08,\n",
    "#     \"weight_decay\": 0,\n",
    "#     \"amsgrad\": False,\n",
    "# }\n",
    "\n",
    "\n",
    "OPTIMIZER_CONFIG = {\n",
    "    \"__name__\": \"AdamW\",\n",
    "    \"lr\": 0.001,\n",
    "    \"betas\": (0.9, 0.999),\n",
    "    \"eps\": 1e-08,\n",
    "    \"weight_decay\": 0.001,\n",
    "    \"amsgrad\": False,\n",
    "}\n",
    "\n",
    "\n",
    "SYSTEM = {\n",
    "    \"__name__\": \"LinODECell\",\n",
    "    \"input_size\": int,\n",
    "    \"kernel_initialization\": \"skew-symmetric\",\n",
    "}\n",
    "\n",
    "EMBEDDING = {\n",
    "    \"__name__\": \"ConcatEmbedding\",\n",
    "    \"input_size\": int,\n",
    "    \"hidden_size\": int,\n",
    "}\n",
    "FILTER = {\n",
    "    \"__name__\": \"SequentialFilter\",\n",
    "    \"input_size\": int,\n",
    "    \"hidden_size\": int,\n",
    "    \"autoregressive\": True,\n",
    "}\n",
    "\n",
    "# FILTER = {\n",
    "#     \"__name__\": \"RecurrentCellFilter\",\n",
    "#     \"concat\": True,\n",
    "#     \"input_size\": int,\n",
    "#     \"hidden_size\": int,\n",
    "#     \"autoregressive\": True,\n",
    "#     \"Cell\": {\n",
    "#         \"__name__\": \"GRUCell\",\n",
    "#         \"input_size\": int,\n",
    "#         \"hidden_size\": int,\n",
    "#         \"bias\": True,\n",
    "#         \"device\": None,\n",
    "#         \"dtype\": None,\n",
    "#     },\n",
    "# }\n",
    "from linodenet.models.encoders import ResNet, iResNet\n",
    "\n",
    "# ENCODER = {\"__name__\": \"ResNet\", \"__module__\": \"linodenet.models.encoders\",\"input_size\": int, \"nblocks\": 5, \"rezero\": True}\n",
    "# DECODER = {\"__name__\": \"ResNet\", \"__module__\": \"linodenet.models.encoders\",\"input_size\": int, \"nblocks\": 5, \"rezero\": True}\n",
    "\n",
    "\n",
    "LR_SCHEDULER_CONFIG = {\n",
    "    \"__name__\": \"ReduceLROnPlateau\",\n",
    "    \"mode\": \"min\",\n",
    "    # (str) – One of min, max. In min mode, lr will be reduced when the quantity monitored has stopped decreasing; in max mode it will be reduced when the quantity monitored has stopped increasing. Default: ‘min’.\n",
    "    \"factor\": 0.1,\n",
    "    # (float) – Factor by which the learning rate will be reduced. new_lr = lr * factor. Default: 0.1.\n",
    "    \"patience\": 10,\n",
    "    # (int) – Number of epochs with no improvement after which learning rate will be reduced. For example, if patience = 2, then we will ignore the first 2 epochs with no improvement, and will only decrease the LR after the 3rd epoch if the loss still hasn’t improved then. Default: 10.\n",
    "    \"threshold\": 0.0001,\n",
    "    # (float) – Threshold for measuring the new optimum, to only focus on significant changes. Default: 1e-4.\n",
    "    \"threshold_mode\": \"rel\",\n",
    "    # (str) – One of rel, abs. In rel mode, dynamic_threshold = best * ( 1 + threshold ) in ‘max’ mode or best * ( 1 - threshold ) in min mode. In abs mode, dynamic_threshold = best + threshold in max mode or best - threshold in min mode. Default: ‘rel’.\n",
    "    \"cooldown\": 0,\n",
    "    # (int) – Number of epochs to wait before resuming normal operation after lr has been reduced. Default: 0.\n",
    "    \"min_lr\": 1e-08,\n",
    "    # (float or list) – A scalar or a list of scalars. A lower bound on the learning rate of all param groups or each group respectively. Default: 0.\n",
    "    \"eps\": 1e-08,\n",
    "    # (float) – Minimal decay applied to lr. If the difference between new and old lr is smaller than eps, the update is ignored. Default: 1e-8.\n",
    "    \"verbose\": True,\n",
    "    # (bool) – If True, prints a message to stdout for each update. Default: False.\n",
    "}\n",
    "\n",
    "MODEL_CONFIG = {\n",
    "    \"__name__\": \"LinODEnet\",\n",
    "    \"input_size\": NUM_DIM,\n",
    "    \"hidden_size\": 128,\n",
    "    \"embedding_type\": \"concat\",\n",
    "    \"Filter\": SequentialFilter.HP,\n",
    "    \"System\": SYSTEM,\n",
    "    \"Encoder\": ResNet.HP,\n",
    "    \"Decoder\": ResNet.HP,\n",
    "    \"Embedding\": EMBEDDING,\n",
    "}\n",
    "\n",
    "\n",
    "HPARAMS = join_dicts({\n",
    "    \"Optimizer\": OPTIMIZER_CONFIG,\n",
    "    \"LR_Scheduler\": LR_SCHEDULER_CONFIG,\n",
    "    \"Model\": MODEL_CONFIG,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d695b42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = LinODEnet\n",
    "model = MODEL(**MODEL_CONFIG)\n",
    "model.to(device=DEVICE, dtype=DTYPE)\n",
    "torchinfo.summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211ce43a-8480-419d-b34c-c548c4c8ddce",
   "metadata": {},
   "outputs": [],
   "source": [
    "jit.save(model, \"model.pt\")\n",
    "model = jit.load(\"model.pt\")\n",
    "torchinfo.summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae43ba99-5e11-4375-80b0-12cd4acda11e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
