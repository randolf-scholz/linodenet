{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InteractiveShell.ast_node_interactivity='last_expr_or_assign'\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import math\n",
    "from abc import abstractmethod\n",
    "from collections.abc import Callable, Iterator, Mapping, Sequence\n",
    "from dataclasses import KW_ONLY, dataclass\n",
    "from datetime import timedelta as py_td\n",
    "from itertools import chain, count\n",
    "from typing import (\n",
    "    Any,\n",
    "    ClassVar,\n",
    "    Final,\n",
    "    Generic,\n",
    "    Literal,\n",
    "    Optional,\n",
    "    Protocol,\n",
    "    TypeVar,\n",
    "    cast,\n",
    "    overload,\n",
    "    reveal_type,\n",
    "    runtime_checkable,\n",
    ")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "from numpy.typing import NDArray\n",
    "from pandas import DataFrame, Index, Series, Timedelta, Timestamp\n",
    "from tsdm.random.samplers import SlidingWindowSampler\n",
    "from tsdm.types.protocols import Lookup\n",
    "from tsdm.types.time import DTVar, NumpyDTVar, NumpyTDVar, TDVar\n",
    "from tsdm.types.variables import (\n",
    "    any_co as T_co,\n",
    "    any_var as T,\n",
    "    key_other_var as K2,\n",
    "    key_var as K,\n",
    ")\n",
    "from tsdm.utils.data.datasets import Dataset, IterableDataset, MapDataset\n",
    "from tsdm.utils.strings import pprint_repr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tds = Series(pd.to_timedelta(np.random.rand(200), \"m\"))\n",
    "tmin = pd.Timestamp(0)\n",
    "tmax = tmin + pd.Timedelta(2, \"h\")\n",
    "T = pd.concat([Series([tmin]), tmin + tds.cumsum(), Series([tmax])])\n",
    "T = T.reset_index(drop=True)\n",
    "\n",
    "stride = \"5m\"\n",
    "# mode = \"points\"\n",
    "horizons = \"15m\"\n",
    "shuffle = False\n",
    "\n",
    "sampler = SlidingWindowSampler(\n",
    "    T, stride=stride, horizons=horizons, mode=\"points\", shuffle=shuffle\n",
    ")\n",
    "indices = list(sampler)\n",
    "X = DataFrame(np.random.randn(len(T), 2), columns=[\"ch1\", \"ch2\"], index=T)\n",
    "assert len(indices) >= 0 and len(X) > 0  # TODO: implement test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODE = TypeVar(\"MODE\", Literal[\"masks\"], Literal[\"slices\"], Literal[\"points\"])\n",
    "Modes = TypeVar(\"Modes\", bound=Literal[\"masks\", \"slices\", \"points\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Foo: ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self = Foo()\n",
    "\n",
    "data_source = T\n",
    "horizons: str | Sequence[str] | NumpyTDVar | Sequence[NumpyTDVar]\n",
    "mode: MODE = (\"masks\",)  # type: ignore[assignment\n",
    "shuffle: bool = False\n",
    "stride: str | NumpyTDVar\n",
    "tmax: Optional[str | NumpyDTVar] = None\n",
    "tmin: Optional[str | NumpyDTVar] = None\n",
    "self.data = np.asarray(data_source)\n",
    "self.mode = mode\n",
    "self.stride = Timedelta(stride) if isinstance(stride, str) else stride\n",
    "\n",
    "match tmin:\n",
    "    case None:\n",
    "        self.tmin = self.data.iloc[0] if isinstance(self.data, Series) else self.data[0]\n",
    "    case str() as time_str:\n",
    "        self.tmin = Timestamp(time_str)\n",
    "    case _:\n",
    "        self.tmin = tmin\n",
    "\n",
    "match tmax:\n",
    "    case None:\n",
    "        self.tmax = (\n",
    "            self.data.iloc[-1] if isinstance(self.data, Series) else self.data[-1]\n",
    "        )\n",
    "    case str() as time_str:\n",
    "        self.tmax = Timestamp(time_str)\n",
    "    case _:\n",
    "        self.tmax = tmax\n",
    "\n",
    "# this gives us the correct zero, depending on the dtype\n",
    "self.zero_td = cast(NumpyTDVar, self.tmin - self.tmin)  # type: ignore[redundant-cast]\n",
    "assert self.stride > self.zero_td, \"stride cannot be zero.\"\n",
    "\n",
    "# convert horizons to timedelta\n",
    "horizons = Timedelta(horizons) if isinstance(horizons, str) else horizons\n",
    "if isinstance(horizons, Sequence):\n",
    "    self.multi_horizon = True\n",
    "    if isinstance(horizons[0], str | Timedelta | py_td):\n",
    "        self.horizons = pd.to_timedelta(horizons)\n",
    "        concat_horizons = self.horizons.insert(0, self.zero_td)  # type: ignore[union-attr]\n",
    "    else:\n",
    "        self.horizons = np.array(horizons)\n",
    "        concat_horizons = np.concatenate(([self.zero_td], self.horizons))  # type: ignore[arg-type]\n",
    "\n",
    "    self.cumulative_horizons = np.cumsum(concat_horizons)\n",
    "    self.total_horizon = self.cumulative_horizons[-1]\n",
    "else:\n",
    "    self.multi_horizon = False\n",
    "    self.horizons = horizons\n",
    "    self.total_horizon = self.horizons\n",
    "    self.cumulative_horizons = np.cumsum([self.zero_td, self.horizons])\n",
    "\n",
    "self.start_values = self.tmin + self.cumulative_horizons  # type: ignore[assignment, call-overload, operator]\n",
    "\n",
    "self.offset = self.tmin + self.total_horizon  # type: ignore[assignment, call-overload, operator]\n",
    "\n",
    "# precompute the possible slices\n",
    "grid = compute_grid(self.tmin, self.tmax, self.stride, offset=self.offset)\n",
    "self.grid = grid[grid >= 0]  # type: ignore[assignment, operator]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance(\"123\", Sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.tmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.zero_td"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.cumsum([self.zero_td, self.horizons])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.cumulative_horizons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.cumsum(np.array([self.zero_td, self.horizons]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, computed_field, dataclasses\n",
    "\n",
    "\n",
    "@dataclasses.dataclass(slots=True)\n",
    "class Rectangle:\n",
    "    width: int\n",
    "    length: int\n",
    "\n",
    "    @computed_field\n",
    "    # @property\n",
    "    def area(self) -> int:\n",
    "        return self.width * self.length\n",
    "\n",
    "\n",
    "# print(Rectangle(width=3, length=2).model_dump())\n",
    "# > {'width': 3, 'length': 2, 'area': 6}\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "obj = Rectangle(width=np.float32(3.0), length=2)\n",
    "obj.area\n",
    "# obj.__slots__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InteractiveShell.ast_node_interactivity='last_expr_or_assign'\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "pyflyby-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "print(\n",
    "    ast.dump(\n",
    "        ast.parse(\"\"\"\n",
    "\n",
    "from collections.abc import Sequence, Union\n",
    "\n",
    "\n",
    "def foo(x) -> int | float: ...\n",
    "\"\"\"),\n",
    "        indent=4,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import array\n",
    "\n",
    "arr = array.array(\"i\", [1, 2, 3])\n",
    "\n",
    "arr = bytes(\"agagaga\", encoding=\"utf8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [torch.randn(2), torch.randn(3)]\n",
    "\n",
    "match x:\n",
    "    case Tensor(a), Tensor(b):\n",
    "        print(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from pathlib import Path\n",
    "from typing import Any, Optional, Protocol, cast, runtime_checkable\n",
    "\n",
    "import torch\n",
    "import torch.utils.cpp_extension\n",
    "from torch import Tensor\n",
    "\n",
    "# constants\n",
    "# we use FP32 machine epsilon as default tolerance\n",
    "ATOL = 1e-6  # 2**-23  # ~1.19e-7\n",
    "RTOL = 1e-6  # 2**-23  # ~1.19e-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectral_norm_debug(\n",
    "    A: Tensor,\n",
    "    u0: Optional[Tensor] = None,\n",
    "    v0: Optional[Tensor] = None,\n",
    "    maxiter: Optional[int] = None,\n",
    "    atol: float = ATOL,\n",
    "    rtol: float = RTOL,\n",
    ") -> Tensor:\n",
    "    \"\"\"Computes the spectral norm.\"\"\"\n",
    "    return _spectral_norm_debug(A, u0, v0, maxiter, atol, rtol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type.__signature__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Sequence\n",
    "from math import prod, sqrt\n",
    "from typing import Optional, Protocol, Union, runtime_checkable\n",
    "\n",
    "import torch\n",
    "import torch.linalg\n",
    "from numpy.typing import NDArray\n",
    "from scipy import stats\n",
    "from torch import BoolTensor, Tensor, jit, nn\n",
    "from torch.optim import SGD\n",
    "\n",
    "import linodenet\n",
    "from linodenet.constants import TRUE\n",
    "from linodenet.parametrize import *\n",
    "from linodenet.projections import functional as projections\n",
    "from linodenet.testing import check_jit_serialization\n",
    "from linodenet.types import Device, Dtype, Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils.parametrize as P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U = torch.randn(5, 5)\n",
    "x = torch.randn(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.einsum(\"ij, k -> ik\", U, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Mapping, Sized\n",
    "\n",
    "\n",
    "class Foo(Sized):\n",
    "    def __iter__(self): ...\n",
    "\n",
    "    def __len__(self): ...\n",
    "\n",
    "\n",
    "class Bar(Foo, Mapping):\n",
    "    def __getitem__(self, key): ...\n",
    "\n",
    "\n",
    "hash(Foo())  # ✔\n",
    "hash(Bar())  # ✘ TypeError: unhashable type: 'Bar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool((torch.linalg.matrix_rank(torch.randn(7, 5, 5)) <= 6).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bar.__eq__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bar.mro()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RankOne(nn.Module):\n",
    "    def forward(self, x, y):\n",
    "        # Form a rank 1 matrix multiplying two vectors\n",
    "        return x.unsqueeze(-1) @ y.unsqueeze(-2)\n",
    "\n",
    "    def right_inverse(self, Z):\n",
    "        # Project Z onto the rank 1 matrices\n",
    "        U, S, Vh = torch.linalg.svd(Z, full_matrices=False)\n",
    "        # Return rescaled singular vectors\n",
    "        s0_sqrt = S[0].sqrt().unsqueeze(-1)\n",
    "        return U[..., :, 0] * s0_sqrt, Vh[..., 0, :] * s0_sqrt\n",
    "\n",
    "\n",
    "model = nn.Linear(4, 4)\n",
    "print(hash(model))\n",
    "print(dict(model.named_parameters()))\n",
    "linear_rank_one = P.register_parametrization(model, \"weight\", RankOne())\n",
    "print(hash(linear_rank_one))\n",
    "\n",
    "print(torch.linalg.matrix_rank(linear_rank_one.weight).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(linear_rank_one.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B, N, M = 7, 3, 5\n",
    "inputs = torch.randn(B, N)\n",
    "targets = torch.randn(B, M)\n",
    "model = nn.Linear(in_features=N, out_features=M, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# register_parametrization(model, \"weight\", UpperTriangular)\n",
    "param = UpperTriangular(model.weight)\n",
    "delattr(model, \"weight\")\n",
    "model.register_buffer(\"weight\", param.cached_parameter)\n",
    "model.register_module(\"weight_parametrization\", param)\n",
    "model.register_parameter(\"weight_original\", param.original_parameter)\n",
    "dict(model.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scripted = jit.script(model)\n",
    "dict(scripted.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = check_jit_serialization(scripted)\n",
    "loaded.weight_parametrization.update_parametrization()\n",
    "optim = SGD(loaded.parameters(), lr=0.1)\n",
    "dict(loaded.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    original_loss = (loaded(inputs) - targets).norm()\n",
    "    print(original_loss)\n",
    "\n",
    "loaded.weight, loaded.weight_original, loaded.weight_parametrization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded.zero_grad(set_to_none=True)\n",
    "loss = (loaded(inputs) - targets).norm()\n",
    "print(loss)\n",
    "loss.backward()\n",
    "optim.step()\n",
    "loaded.weight_parametrization.update_parametrization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(loaded.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss < original_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
