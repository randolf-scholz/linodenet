{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%config InteractiveShell.ast_node_interactivity='last_expr_or_assign'\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "from contextlib import AbstractContextManager\n",
    "from typing import Protocol, runtime_checkable\n",
    "\n",
    "import torch\n",
    "from torch import Tensor, jit, nn, tensor\n",
    "from torch.linalg import matrix_norm\n",
    "\n",
    "# from linodenet.lib import singular_triplet\n",
    "from torchinfo import summary\n",
    "\n",
    "# from linodenet.parametrize import Parametrization, SpectralNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deprecated(func=None, msg=None, /, *, category=DeprecationWarning, stacklevel=1):\n",
    "    \"\"\"Indicate that a class, function or overload is deprecated.\"\"\"\n",
    "    if isinstance(func, str):\n",
    "        # used as deprecated(\"message\") -> shift arguments\n",
    "        assert msg is None\n",
    "        msg = func\n",
    "        func = None\n",
    "\n",
    "    if func is None:\n",
    "        # used with brackets -> decorator factory\n",
    "        def decorator(decorated):\n",
    "            msg = make_default_message(decorated) if msg is None else msg\n",
    "\n",
    "            def wrapped(*args, **kwargs):\n",
    "                ...\n",
    "\n",
    "            return wrapped\n",
    "\n",
    "        return decorator\n",
    "\n",
    "    # used without brackets -> wrap func\n",
    "    msg = make_default_message(func)\n",
    "\n",
    "    def wrapped(*args, **kwargs):\n",
    "        ...\n",
    "\n",
    "    return wrapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections.abc import Callable\n",
    "\n",
    "isinstance(1, Callable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing_extensions import deprecated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deprecated(func_or_msg=None, /, **kwargs):\n",
    "    if isinstance(func_or_message, str):\n",
    "        # used with brackets\n",
    "        def decorator():\n",
    "            def wrapped():\n",
    "                ...\n",
    "\n",
    "            return wrapped\n",
    "\n",
    "        return decorator\n",
    "\n",
    "    # used without brackets\n",
    "    default_message = ...\n",
    "\n",
    "    def wrapped():\n",
    "        ...\n",
    "\n",
    "    return wrapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "foo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.linalg\n",
    "from torch import BoolTensor, Tensor, jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from abc import abstractmethod\n",
    "from collections.abc import Callable\n",
    "from contextlib import AbstractContextManager\n",
    "from typing import Protocol, runtime_checkable\n",
    "\n",
    "import torch\n",
    "from torch import Tensor, jit, nn\n",
    "\n",
    "\n",
    "@runtime_checkable\n",
    "class ParametrizationProto(Protocol):\n",
    "    \"\"\"Protocol for parametrizations.\n",
    "\n",
    "    Note:\n",
    "        To work with JIT, the listed methods must be annotated with @jit.export.\n",
    "    \"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def reset_cache(self) -> None:\n",
    "        \"\"\"Reset the cached weight matrix.\"\"\"\n",
    "        ...\n",
    "\n",
    "    @abstractmethod\n",
    "    def recompute_cache(self) -> None:\n",
    "        \"\"\"Recompute the cached weight matrix.\"\"\"\n",
    "        ...\n",
    "\n",
    "    @abstractmethod\n",
    "    def projection(self) -> None:\n",
    "        \"\"\"Project the cached weight matrix.\"\"\"\n",
    "        ...\n",
    "\n",
    "    @jit.export\n",
    "    def right_inverse(self) -> None:\n",
    "        \"\"\"Compute the right inverse of the parametrization.\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @jit.export\n",
    "    def reset_parameters(self) -> None:\n",
    "        \"\"\"Reapply the initialization.\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class Parametrize(nn.Module, ParametrizationProto):\n",
    "    \"\"\"Parametrization of a single tensor.\"\"\"\n",
    "\n",
    "    # Parameters:\n",
    "    parametrized_tensor: Tensor\n",
    "    # Buffers:\n",
    "    cached_tensor: Tensor\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        tensor: Tensor,\n",
    "        parametrization: Callable[[Tensor], Tensor],\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        # get the tensor to parametrize\n",
    "        self.register_parameter(\"parametrized_tensor\", tensor)\n",
    "        self.register_buffer(\"cached_tensor\", torch.empty_like(tensor))\n",
    "\n",
    "        # get the parametrization\n",
    "        self._parametrization = parametrization\n",
    "\n",
    "    def forward(self) -> Tensor:\n",
    "        \"\"\"Apply the parametrization to the weight matrix.\"\"\"\n",
    "        return self.parametrization(self.parametrized_tensor)\n",
    "\n",
    "    @jit.export\n",
    "    def parametrization(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"Apply the parametrization.\"\"\"\n",
    "        return self._parametrization(x)\n",
    "\n",
    "    @jit.export\n",
    "    def recompute_cache(self) -> None:\n",
    "        # Compute the cached weight matrix\n",
    "        new_tensor = self.forward()\n",
    "        self.cached_tensor.copy_(new_tensor)\n",
    "\n",
    "    @jit.export\n",
    "    def projection(self) -> None:\n",
    "        with torch.no_grad():\n",
    "            # update the cached weight matrix\n",
    "            self.recompute_cache()\n",
    "            self.parametrized_tensor.copy_(self.cached_tensor)\n",
    "\n",
    "    @jit.export\n",
    "    def reset_cache(self) -> None:\n",
    "        # apply projection step.\n",
    "        self.projection()\n",
    "\n",
    "        # reengage the autograd engine\n",
    "        # detach() is necessary to avoid \"Trying to backward through the graph a second time\" error\n",
    "        self.cached_tensor.detach_()\n",
    "\n",
    "        # recompute the cache\n",
    "        # Note: we need the second run to set up the gradients\n",
    "        self.recompute_cache()\n",
    "\n",
    "    @jit.export\n",
    "    def reset_cache_expanded(self) -> None:\n",
    "        with torch.no_grad():\n",
    "            new_tensor = self.forward()\n",
    "            self.cached_tensor.copy_(new_tensor)\n",
    "            self.parametrized_tensor.copy_(self.cached_tensor)\n",
    "\n",
    "        # reengage the autograd engine\n",
    "        # detach() is necessary to avoid \"Trying to backward through the graph a second time\" error\n",
    "        self.cached_tensor.detach_()\n",
    "\n",
    "        # recompute the cache\n",
    "        # Note: we need the second run to set up the gradients\n",
    "        new_tensor = self.forward()\n",
    "        self.cached_tensor.copy_(new_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from linodenet.lib import spectral_norm, spectral_norm_native\n",
    "from linodenet.parametrize import SpectralNormalization\n",
    "from linodenet.projections import is_symmetric, symmetric\n",
    "from linodenet.testing import check_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "B, M, N = 4, 3, 3\n",
    "x = torch.randn(B, M)\n",
    "\n",
    "# setup reference model\n",
    "reference_model = nn.Linear(M, N, bias=False)\n",
    "symmetrized_weight = symmetric(reference_model.weight)\n",
    "reference_model.weight = nn.Parameter(symmetrized_weight)\n",
    "assert is_symmetric(reference_model.weight)\n",
    "\n",
    "# setup vanilla model\n",
    "model = nn.Linear(M, N, bias=False)\n",
    "with torch.no_grad():\n",
    "    model.weight.copy_(reference_model.weight)\n",
    "\n",
    "# check compatibility\n",
    "check_model(model, input_args=(x,), reference_model=reference_model, test_jit=True)\n",
    "\n",
    "# now, parametrize\n",
    "weight = model.weight\n",
    "param = Parametrize(weight, symmetric)\n",
    "param.zero_grad(set_to_none=True)\n",
    "model.weight = param.parametrized_tensor\n",
    "model.param = param\n",
    "\n",
    "# check compatibility\n",
    "check_model(model, input_args=(x,), reference_model=reference_model, test_jit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "m, n = 5, 5\n",
    "tensor = torch.randn(m, n)\n",
    "weight = nn.Parameter(tensor)\n",
    "param = Parametrize(weight, symmetric)\n",
    "param.zero_grad(set_to_none=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = nn.Linear(m, n)\n",
    "weight = model.weight\n",
    "param = Parametrize(weight, symmetric)\n",
    "param.zero_grad(set_to_none=True)\n",
    "model.weight = param.parametrized_tensor\n",
    "model.param = param\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = nn.Linear(m, n, bias=False)\n",
    "with torch.no_grad():\n",
    "    model.weight.copy_(reference_model.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = torch.randn(7, m)\n",
    "check_model(model, input_args=(x,), reference_model=reference_model, test_jit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## now, parametrize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "weight = model.weight\n",
    "param = Parametrize(weight, symmetric)\n",
    "param.zero_grad(set_to_none=True)\n",
    "model.weight = param.parametrized_tensor\n",
    "model.param = param\n",
    "check_model(model, input_args=(x,), reference_model=reference_model, test_jit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "symmetric(reference_model.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scripted = jit.script(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scripted.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scripted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "param.reset_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "param.parametrized_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
