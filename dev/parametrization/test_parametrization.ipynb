{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%config InteractiveShell.ast_node_interactivity='last_expr_or_assign'\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "from contextlib import AbstractContextManager\n",
    "from typing import Protocol, runtime_checkable\n",
    "\n",
    "import torch\n",
    "from torch import Tensor, jit, nn, tensor\n",
    "from torch.linalg import matrix_norm\n",
    "\n",
    "# from linodenet.lib import singular_triplet\n",
    "from torchinfo import summary\n",
    "\n",
    "# from linodenet.parametrize import Parametrization, SpectralNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import linodenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from linodenet.activations.functional import hard_bend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def soft_bend(x):\n",
    "    return torch.arcsinh(torch.exp(torch.tensor(1.0)) * torch.sinh(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "N = 1_000_000\n",
    "x = torch.randn(N)\n",
    "y = hard_bend(x)\n",
    "z = soft_bend(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 10))\n",
    "\n",
    "ax.hist(x, density=True, bins=1000, alpha=0.4)\n",
    "ax.hist(y, density=True, bins=1000, alpha=0.4)\n",
    "ax.hist(z, density=True, bins=1000, alpha=0.4)\n",
    "w = torch.cat([torch.randn(N // 2) + 1.7, torch.randn(N // 2) - 1.7])\n",
    "# ax.hist(w, density=True, bins=100, alpha=0.4);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import enum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Color(enum.Enum):\n",
    "    RED = 1\n",
    "    GREEN = 2\n",
    "    BLUE = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "isinstance(scripted, nn.Module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "from typing import Iterable, List, NamedTuple, Tuple, Union\n",
    "import torch\n",
    "from torch import Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor, nn, jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jit.script(nn.Module.to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pad_sequence(\n",
    "    sequences: Union[Tensor, Iterable[Tensor]],\n",
    "    batch_first: bool = False,\n",
    "    padding_value: float = 0.0,\n",
    ") -> Tensor:\n",
    "    r\"\"\"Pad a list of variable length Tensors with ``padding_value``\n",
    "\n",
    "    ``pad_sequence`` stacks a list of Tensors along a new dimension,\n",
    "    and pads them to equal length. For example, if the input is a list of\n",
    "    sequences with size ``L x *`` and ``batch_first`` is False, the output is\n",
    "    of size ``T x B x *``.\n",
    "\n",
    "    `B` is batch size. It is equal to the number of elements in ``sequences``.\n",
    "    `T` is length of the longest sequence.\n",
    "    `L` is length of the sequence.\n",
    "    `*` is any number of trailing dimensions, including none.\n",
    "\n",
    "    Example:\n",
    "        >>> from torch.nn.utils.rnn import pad_sequence\n",
    "        >>> a = torch.ones(25, 300)\n",
    "        >>> b = torch.ones(22, 300)\n",
    "        >>> c = torch.ones(15, 300)\n",
    "        >>> pad_sequence([a, b, c]).size()\n",
    "        torch.Size([25, 3, 300])\n",
    "\n",
    "    Note:\n",
    "        This function returns a Tensor of size ``T x B x *`` or ``B x T x *``\n",
    "        where `T` is the length of the longest sequence. This function assumes\n",
    "        trailing dimensions and type of all the Tensors in sequences are same.\n",
    "\n",
    "    Args:\n",
    "        sequences (list[Tensor]): list of variable length sequences.\n",
    "        batch_first (bool, optional): output will be in ``B x T x *`` if True, or in\n",
    "            ``T x B x *`` otherwise. Default: False.\n",
    "        padding_value (float, optional): value for padded elements. Default: 0.\n",
    "\n",
    "    Returns:\n",
    "        Tensor of size ``T x B x *`` if :attr:`batch_first` is ``False``.\n",
    "        Tensor of size ``B x T x *`` otherwise\n",
    "    \"\"\"\n",
    "\n",
    "    if not (torch.jit.is_tracing() or torch.jit.is_scripting()):\n",
    "        # JIT doesn't support `Iterable`\n",
    "        if not isinstance(sequences, Iterable):\n",
    "            msg = (\n",
    "                \"pad_sequence: Expected iterable for input sequences, but got arg of type: \"\n",
    "                f\"{type(sequences)}\"\n",
    "            )\n",
    "            raise RuntimeError(msg)\n",
    "\n",
    "        # In JIT context this leads to,\n",
    "        # RuntimeError: cannot statically infer the expected size of a list in this context\n",
    "        sequences = tuple(sequences)\n",
    "    else:\n",
    "        # For JIT, we only support Union[Tensor, Tuple[Tensor]]\n",
    "        if isinstance(sequences, torch.Tensor):\n",
    "            sequences = sequences.unbind(0)\n",
    "\n",
    "    # assuming trailing dimensions and type of all the Tensors\n",
    "    # in sequences are same and fetching those from sequences[0]\n",
    "    return torch._C._nn.pad_sequence(sequences, batch_first, padding_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "type(nn.Linear(4, 4)).__mro__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@jit.script\n",
    "def hard_bend(x: Tensor, a: float = 1, t: float = 1) -> Tensor:\n",
    "    r\"\"\"Hard step activation function.\"\"\"\n",
    "    mask = x.abs() <= t / (torch.exp(a * t) - 1)\n",
    "    return torch.where(mask, torch.exp(a * t) * x, x + torch.sign(x) * t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Union, TYPE_CHECKING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Union[int, str, \"MyClass\"]  # you want the string back?\n",
    "\n",
    "if TYPE_CHECKING:\n",
    "    from collections.abc import Sequence  # not otherwise imported\n",
    "\n",
    "x: Union[Sequence, None]  # what is the first iteration value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "2 in (k for k in range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "isinstance(x, Mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gen = (k for k in range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "7 in gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vars(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "object.__contains__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dir(mod.named_buffers())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hard_bend(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "x.abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "x.abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "torch.abs(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "torch.abs(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "?x.where"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.tensor(1).exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torhc.exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mod = torch.nn.Linear(4, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mod.to(device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.nn.Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def union_isinstance(union, other):\n",
    "    print(\"calling isinstancheck!\")\n",
    "    return isinstance(typing.get_args(union))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deprecated(func=None, msg=None, /, *, category=DeprecationWarning, stacklevel=1):\n",
    "    \"\"\"Indicate that a class, function or overload is deprecated.\"\"\"\n",
    "    if isinstance(func, str):\n",
    "        # used as deprecated(\"message\") -> shift arguments\n",
    "        assert msg is None\n",
    "        msg = func\n",
    "        func = None\n",
    "\n",
    "    if func is None:\n",
    "        # used with brackets -> decorator factory\n",
    "        def decorator(decorated):\n",
    "            msg = make_default_message(decorated) if msg is None else msg\n",
    "\n",
    "            def wrapped(*args, **kwargs):\n",
    "                ...\n",
    "\n",
    "            return wrapped\n",
    "\n",
    "        return decorator\n",
    "\n",
    "    # used without brackets -> wrap func\n",
    "    msg = make_default_message(func)\n",
    "\n",
    "    def wrapped(*args, **kwargs):\n",
    "        ...\n",
    "\n",
    "    return wrapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections.abc import Callable\n",
    "\n",
    "isinstance(1, Callable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing_extensions import deprecated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deprecated(func_or_msg=None, /, **kwargs):\n",
    "    if isinstance(func_or_message, str):\n",
    "        # used with brackets\n",
    "        def decorator():\n",
    "            def wrapped():\n",
    "                ...\n",
    "\n",
    "            return wrapped\n",
    "\n",
    "        return decorator\n",
    "\n",
    "    # used without brackets\n",
    "    default_message = ...\n",
    "\n",
    "    def wrapped():\n",
    "        ...\n",
    "\n",
    "    return wrapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "foo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.linalg\n",
    "from torch import BoolTensor, Tensor, jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from abc import abstractmethod\n",
    "from collections.abc import Callable\n",
    "from contextlib import AbstractContextManager\n",
    "from typing import Protocol, runtime_checkable\n",
    "\n",
    "import torch\n",
    "from torch import Tensor, jit, nn\n",
    "\n",
    "\n",
    "@runtime_checkable\n",
    "class ParametrizationProto(Protocol):\n",
    "    \"\"\"Protocol for parametrizations.\n",
    "\n",
    "    Note:\n",
    "        To work with JIT, the listed methods must be annotated with @jit.export.\n",
    "    \"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def reset_cache(self) -> None:\n",
    "        \"\"\"Reset the cached weight matrix.\"\"\"\n",
    "        ...\n",
    "\n",
    "    @abstractmethod\n",
    "    def recompute_cache(self) -> None:\n",
    "        \"\"\"Recompute the cached weight matrix.\"\"\"\n",
    "        ...\n",
    "\n",
    "    @abstractmethod\n",
    "    def projection(self) -> None:\n",
    "        \"\"\"Project the cached weight matrix.\"\"\"\n",
    "        ...\n",
    "\n",
    "    @jit.export\n",
    "    def right_inverse(self) -> None:\n",
    "        \"\"\"Compute the right inverse of the parametrization.\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @jit.export\n",
    "    def reset_parameters(self) -> None:\n",
    "        \"\"\"Reapply the initialization.\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class Parametrize(nn.Module, ParametrizationProto):\n",
    "    \"\"\"Parametrization of a single tensor.\"\"\"\n",
    "\n",
    "    # Parameters:\n",
    "    parametrized_tensor: Tensor\n",
    "    # Buffers:\n",
    "    cached_tensor: Tensor\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        tensor: Tensor,\n",
    "        parametrization: Callable[[Tensor], Tensor],\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        # get the tensor to parametrize\n",
    "        self.register_parameter(\"parametrized_tensor\", tensor)\n",
    "        self.register_buffer(\"cached_tensor\", torch.empty_like(tensor))\n",
    "\n",
    "        # get the parametrization\n",
    "        self._parametrization = parametrization\n",
    "\n",
    "    def forward(self) -> Tensor:\n",
    "        \"\"\"Apply the parametrization to the weight matrix.\"\"\"\n",
    "        return self.parametrization(self.parametrized_tensor)\n",
    "\n",
    "    @jit.export\n",
    "    def parametrization(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"Apply the parametrization.\"\"\"\n",
    "        return self._parametrization(x)\n",
    "\n",
    "    @jit.export\n",
    "    def recompute_cache(self) -> None:\n",
    "        # Compute the cached weight matrix\n",
    "        new_tensor = self.forward()\n",
    "        self.cached_tensor.copy_(new_tensor)\n",
    "\n",
    "    @jit.export\n",
    "    def projection(self) -> None:\n",
    "        with torch.no_grad():\n",
    "            # update the cached weight matrix\n",
    "            self.recompute_cache()\n",
    "            self.parametrized_tensor.copy_(self.cached_tensor)\n",
    "\n",
    "    @jit.export\n",
    "    def reset_cache(self) -> None:\n",
    "        # apply projection step.\n",
    "        self.projection()\n",
    "\n",
    "        # reengage the autograd engine\n",
    "        # detach() is necessary to avoid \"Trying to backward through the graph a second time\" error\n",
    "        self.cached_tensor.detach_()\n",
    "\n",
    "        # recompute the cache\n",
    "        # Note: we need the second run to set up the gradients\n",
    "        self.recompute_cache()\n",
    "\n",
    "    @jit.export\n",
    "    def reset_cache_expanded(self) -> None:\n",
    "        with torch.no_grad():\n",
    "            new_tensor = self.forward()\n",
    "            self.cached_tensor.copy_(new_tensor)\n",
    "            self.parametrized_tensor.copy_(self.cached_tensor)\n",
    "\n",
    "        # reengage the autograd engine\n",
    "        # detach() is necessary to avoid \"Trying to backward through the graph a second time\" error\n",
    "        self.cached_tensor.detach_()\n",
    "\n",
    "        # recompute the cache\n",
    "        # Note: we need the second run to set up the gradients\n",
    "        new_tensor = self.forward()\n",
    "        self.cached_tensor.copy_(new_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from linodenet.lib import spectral_norm, spectral_norm_native\n",
    "from linodenet.parametrize import SpectralNormalization\n",
    "from linodenet.projections import is_symmetric, symmetric\n",
    "from linodenet.testing import check_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "B, M, N = 4, 3, 3\n",
    "x = torch.randn(B, M)\n",
    "\n",
    "# setup reference model\n",
    "reference_model = nn.Linear(M, N, bias=False)\n",
    "symmetrized_weight = symmetric(reference_model.weight)\n",
    "reference_model.weight = nn.Parameter(symmetrized_weight)\n",
    "assert is_symmetric(reference_model.weight)\n",
    "\n",
    "# setup vanilla model\n",
    "model = nn.Linear(M, N, bias=False)\n",
    "with torch.no_grad():\n",
    "    model.weight.copy_(reference_model.weight)\n",
    "\n",
    "# check compatibility\n",
    "check_model(model, input_args=(x,), reference_model=reference_model, test_jit=True)\n",
    "\n",
    "# now, parametrize\n",
    "weight = model.weight\n",
    "param = Parametrize(weight, symmetric)\n",
    "param.zero_grad(set_to_none=True)\n",
    "model.weight = param.parametrized_tensor\n",
    "model.param = param\n",
    "\n",
    "# check compatibility\n",
    "check_model(model, input_args=(x,), reference_model=reference_model, test_jit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "m, n = 5, 5\n",
    "tensor = torch.randn(m, n)\n",
    "weight = nn.Parameter(tensor)\n",
    "param = Parametrize(weight, symmetric)\n",
    "param.zero_grad(set_to_none=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = nn.Linear(m, n)\n",
    "weight = model.weight\n",
    "param = Parametrize(weight, symmetric)\n",
    "param.zero_grad(set_to_none=True)\n",
    "model.weight = param.parametrized_tensor\n",
    "model.param = param\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = nn.Linear(m, n, bias=False)\n",
    "with torch.no_grad():\n",
    "    model.weight.copy_(reference_model.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = torch.randn(7, m)\n",
    "check_model(model, input_args=(x,), reference_model=reference_model, test_jit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## now, parametrize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "weight = model.weight\n",
    "param = Parametrize(weight, symmetric)\n",
    "param.zero_grad(set_to_none=True)\n",
    "model.weight = param.parametrized_tensor\n",
    "model.param = param\n",
    "check_model(model, input_args=(x,), reference_model=reference_model, test_jit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "symmetric(reference_model.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scripted = jit.script(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scripted.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scripted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "param.reset_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "param.parametrized_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
