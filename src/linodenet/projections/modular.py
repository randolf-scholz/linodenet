r"""Projections for the Linear ODE Networks.

Notes
-----
Contains projections in modular form.
  - See `~linodenet.projections.functional` for functional implementations.
"""

__all__ = [
    # Base Classes
    "ProjectionABC",
    # Classes
    "Hamiltonian",
    "Identity",
    "Normal",
    "Orthogonal",
    "SkewSymmetric",
    "Symmetric",
    "Symplectic",
    "Traceless",
    # Masked
    "Banded",
    "Diagonal",
    "LowerTriangular",
    "Masked",
    "UpperTriangular",
]

from abc import abstractmethod
from typing import Final, Optional

import torch
from torch import BoolTensor, Tensor, jit, nn

from linodenet.projections.functional import (
    banded,
    diagonal,
    hamiltonian,
    identity,
    lower_triangular,
    masked,
    normal,
    orthogonal,
    skew_symmetric,
    symmetric,
    symplectic,
    traceless,
    upper_triangular,
)


class ProjectionABC(nn.Module):
    """Abstract Base Class for Projection components."""

    @abstractmethod
    def forward(self, z: Tensor, /) -> Tensor:
        r"""Forward pass of the projection.

        .. Signature: ``(..., d) -> (..., f)``.

        Args:
            z: The input tensor to be projected.

        Returns:
            x: The projected tensor.
        """


# region projections -------------------------------------------------------------------
class Identity(nn.Module):
    r"""Return x as-is.

    .. Signature:: ``(..., n, n) -> (..., n, n)``

    .. math:: \min_Y Â½âˆ¥X-Yâˆ¥_F^2
    """

    @jit.export
    def forward(self, x: Tensor) -> Tensor:
        r"""Project x into space of matrices."""
        return identity(x)


class Symmetric(nn.Module):
    r"""Return the closest symmetric matrix to X.

    .. Signature:: ``(..., n, n) -> (..., n, n)``

    .. math:: \min_Y Â½âˆ¥X-Yâˆ¥_F^2 s.t. Y^âŠ¤ = Y

    One can show analytically that Y = Â½(X + X^âŠ¤) is the unique minimizer.
    """

    @jit.export
    def forward(self, x: Tensor) -> Tensor:
        r"""Project x into space of symmetric matrices."""
        return symmetric(x)


class SkewSymmetric(nn.Module):
    r"""Return the closest skew-symmetric matrix to X.

    .. Signature:: ``(..., n, n) -> (..., n, n)``

    .. math:: \min_Y Â½âˆ¥X-Yâˆ¥_F^2 s.t. Y^âŠ¤ = -Y

    One can show analytically that Y = Â½(X - X^âŠ¤) is the unique minimizer.
    """

    @jit.export
    def forward(self, x: Tensor) -> Tensor:
        r"""Project x into space of skew-symmetric matrices."""
        return skew_symmetric(x)


class Orthogonal(nn.Module):
    r"""Return the closest orthogonal matrix to X.

    .. Signature:: ``(..., n, n) -> (..., n, n)``

    .. math:: \min_Y Â½âˆ¥X-Yâˆ¥_F^2 s.t. Y^ğ–³ Y = ğ•€ = YY^ğ–³

    One can show analytically that $Y = UV^ğ–³$ is the unique minimizer,
    where $X=UÎ£V^ğ–³$ is the SVD of $X$.

    References
    ----------
    - `<https://math.stackexchange.com/q/2215359>`_
    """

    @jit.export
    def forward(self, x: Tensor) -> Tensor:
        r"""Project x into space of orthogonal matrices."""
        return orthogonal(x)


class Normal(nn.Module):
    r"""Return the closest normal matrix to X.

    .. Signature:: ``(..., n, n) -> (..., n, n)``

    .. math:: \min_Y Â½âˆ¥X-Yâˆ¥_F^2 s.t. Y^âŠ¤Y = YY^âŠ¤

    **The Lagrangian:**

    .. math:: â„’(Y, Î›) = Â½âˆ¥X-Yâˆ¥_F^2 + âŸ¨Î›, [Y, Y^âŠ¤]âŸ©

    **First order necessary KKT condition:**

    .. math::
            0 &= âˆ‡â„’(Y, Î›) = (Y-X) + Y(Î› + Î›^âŠ¤) - (Î› + Î›^âŠ¤)Y
        \\âŸº Y &= X + [Y, Î›]

    **Second order sufficient KKT condition:**

    .. math::
             âŸ¨âˆ‡h|SâŸ©=0     &âŸ¹ âŸ¨S|âˆ‡Â²â„’|SâŸ© â‰¥ 0
         \\âŸº âŸ¨[Y, Î›]|SâŸ©=0 &âŸ¹ âŸ¨S|ğ•€âŠ—ğ•€ + Î›âŠ—ğ•€ âˆ’ ğ•€âŠ—Î›|SâŸ© â‰¥ 0
         \\âŸº âŸ¨[Y, Î›]|SâŸ©=0 &âŸ¹ âŸ¨S|SâŸ© + âŸ¨[S, Î›]|SâŸ© â‰¥ 0
    """

    @jit.export
    def forward(self, x: Tensor) -> Tensor:
        r"""Project x into space of normal matrices."""
        return normal(x)


class Traceless(nn.Module):
    r"""Return the closest traceless matrix to X.

    .. Signature:: ``(..., n, n) -> (..., n, n)``

    .. math:: \min_Y Â½âˆ¥X-Yâˆ¥_F^2 s.t. Y^âŠ¤ = -Y

    One can show analytically that Y = Â½(X - X^âŠ¤) is the unique minimizer.
    """

    @jit.export
    def forward(self, x: Tensor) -> Tensor:
        r"""Project x into space of traceless matrices."""
        return traceless(x)


class Hamiltonian(nn.Module):
    r"""Return the closest symplectic matrix to X.

    .. Signature:: ``(..., 2n, 2n) -> (..., 2n, 2n)``

    .. math:: \min_Y Â½âˆ¥X-Yâˆ¥_F^2   s.t.   Y^ğ–³ J Y = J   where   J=[ğŸ, ğ•€; -ğ•€, ğŸ]

    Alternatively, the above is equivalent to

    .. math:: \min_Y Â½âˆ¥X-Yâˆ¥_F^2   s.t.   Y^ğ–³ J Y = J   where   J= ğ”»â‚Šâ‚-ğ”»â‚‹â‚

    where $ğ”»â‚–$ is the $2nÃ—2n$ matrix with ones on the k-th diagonal.
    """

    def forward(self, x: Tensor) -> Tensor:
        return hamiltonian(x)


class Symplectic(nn.Module):
    r"""Return the closest symplectic matrix to X.

    .. Signature:: ``(..., 2n, 2n) -> (..., 2n, 2n)``

    .. math:: \min_Y Â½âˆ¥X-Yâˆ¥_F^2   s.t.   Y^ğ–³ J Y = J   where   J=[ğŸ, ğ•€; -ğ•€, ğŸ]

    Alternatively, the above is equivalent to

    .. math:: \min_Y Â½âˆ¥X-Yâˆ¥_F^2   s.t.   Y^ğ–³ J Y = J   where   J= ğ”»â‚Šâ‚-ğ”»â‚‹â‚

    where $ğ”»â‚–$ is the $2nÃ—2n$ matrix with ones on the k-th diagonal.
    """

    def forward(self, x: Tensor) -> Tensor:
        return symplectic(x)


# region masked projections ------------------------------------------------------------
class Diagonal(nn.Module):
    r"""Return the closest diagonal matrix to X.

    .. Signature:: ``(..., n, n) -> (..., n, n)``

    .. math:: \min_Y Â½âˆ¥X-Yâˆ¥_F^2 s.t. Y = ğ•€âŠ™Y

    One can show analytically that the unique smallest norm minimizer is $Y = ğ•€âŠ™X$.

    See Also:
        - `projections.Masked`
        - `projections.Diagonal`
        - `projections.LowerTriangular`
        - `projections.UpperTriangular`
        - `projections.Banded`
    """

    @jit.export
    def forward(self, x: Tensor) -> Tensor:
        r"""Project x into space of diagonal matrices."""
        return diagonal(x)


class Banded(nn.Module):
    r"""Return the closest banded matrix to X.

    .. Signature:: ``(..., n, n) -> (..., n, n)``

    .. math:: \min_Y Â½âˆ¥X-Yâˆ¥_F^2 s.t. Y = ğ”¹âŠ™Y

    One can show analytically that the unique smallest norm minimizer is $Y = ğ”¹âŠ™X$.

    See Also:
        - `projections.Masked`
        - `projections.Diagonal`
        - `projections.LowerTriangular`
        - `projections.UpperTriangular`
        - `projections.Banded`
    """

    upper: Final[int]
    lower: Final[int]

    def __init__(self, upper: int = 0, lower: Optional[int] = None) -> None:
        super().__init__()
        self.upper = upper
        self.lower = upper if lower is None else lower

    @jit.export
    def forward(self, x: Tensor) -> Tensor:
        r"""Project x into space of banded matrices."""
        return banded(x, upper=self.upper, lower=self.lower)


class UpperTriangular(nn.Module):
    r"""Return the closest upper triangular matrix to X.

    .. Signature:: ``(..., m, n) -> (..., m, n)``

    .. math:: \min_Y Â½âˆ¥X-Yâˆ¥_F^2   s.t.   ğ•ŒâŠ™Y = Y

    One can show analytically that the unique smallest norm minimizer is $Y = ğ•ŒâŠ™X$.

    See Also:
        - `projections.Masked`
        - `projections.Diagonal`
        - `projections.LowerTriangular`
        - `projections.UpperTriangular`
        - `projections.Banded`
    """

    upper: Final[int]

    def __init__(self, upper: int = 0) -> None:
        super().__init__()
        self.upper = upper

    @jit.export
    def forward(self, x: Tensor) -> Tensor:
        r"""Project x into space of upper triangular matrices."""
        return upper_triangular(x, upper=self.upper)


class LowerTriangular(nn.Module):
    r"""Return the closest lower triangular matrix to X.

    .. Signature:: ``(..., m, n) -> (..., m, n)``

    .. math:: \min_Y Â½âˆ¥X-Yâˆ¥_F^2   s.t.   ğ•ƒâŠ™Y = Y

    One can show analytically that the unique smallest norm minimizer is $Y = ğ•ƒâŠ™X$.

    See Also:
        - `projections.Masked`
        - `projections.Diagonal`
        - `projections.LowerTriangular`
        - `projections.UpperTriangular`
        - `projections.Banded`
    """

    lower: Final[int]

    def __init__(self, lower: int = 0) -> None:
        super().__init__()
        self.lower = lower

    @jit.export
    def forward(self, x: Tensor) -> Tensor:
        r"""Project x into space of lower triangular matrices."""
        return lower_triangular(x, lower=self.lower)


class Masked(nn.Module):
    r"""Return the closest banded matrix to X.

    .. Signature:: ``(..., n, n) -> (..., n, n)``

    .. math:: \min_Y Â½âˆ¥X-Yâˆ¥_F^2 s.t. Y = ğ•„âŠ™Y

    One can show analytically that the unique smallest norm minimizer is $Y = ğ•„âŠ™X$.

    See Also:
        - `projections.Masked`
        - `projections.Diagonal`
        - `projections.LowerTriangular`
        - `projections.UpperTriangular`
        - `projections.Banded`
    """

    mask: BoolTensor

    def __init__(self, mask: bool | Tensor) -> None:
        super().__init__()
        self.mask = torch.as_tensor(mask, dtype=torch.bool)  # type: ignore[assignment]

    @jit.export
    def forward(self, x: Tensor) -> Tensor:
        r"""Project x into space of masked matrices."""
        return masked(x, self.mask)


# endregion masked projections ---------------------------------------------------------
# endregion projections ----------------------------------------------------------------
