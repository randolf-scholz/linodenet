#include <c10/util/irange.h>
#include <torch/script.h>

#include <cstddef>
#include <string>

struct SpectralNormalization: public torch::autograd::Function<SpectralNormalization> {


    static torch::Tensor forward(
        torch::autograd::AutogradContext *ctx,
        torch::Tensor A,
        int64_t maxiter,
        float32_t atol,
        float32_t rtol,
    ) {
    //    perform power-iteration for maxiter times or until convergence.
        ctx->saved_data["A"] = A;
        ctx->save_for_backward({A});

        torch::Tensor u = torch::randn(A.size(0), 1, dtype=A.dtype(), device=A.device());
        torch::Tensor v = torch::randn(A.size(1), 1, dtype=A.dtype(), device=A.device());

        for (const auto i : c10::irange(maxiter)) {
            torch::Tensor v_new = torch::matmul(A.t(), u);
            v_new /= torch::norm(v_new);
            torch::Tensor u_new = torch::matmul(A, v_new);
            u_new /= torch::norm(u_new);
            if (torch::norm(v - v_new) < atol + rtol * torch::norm(v)) {
                break;
            }
            v = v_new;
            u = u_new;
        }
//        emit warning if no convergence within maxiter iterations
        if (i == maxiter - 1) {
            TORCH_WARN("Spectral norm estimation did not converge");
        }
        torch::Tensor sigma = torch::matmul(u.t(), torch::matmul(A, v));
        ctx->saved_data["u"] = u;
        ctx->saved_data["v"] = v;
        ctx->saved_data["sigma"] = sigma;
        return sigma;

    }

    static torch::autograd::variable_list backward(
        torch::autograd::AutogradContext *ctx,
        torch::autograd::variable_list grad_output
    ) {
        int mul = ctx->saved_data["mul"].toInt();
        bool var3_has_value = ctx->saved_data["var3_has_value"].toBool();
        auto saved = ctx->get_saved_variables();
        auto var1 = saved[0];
        auto var2 = saved[1];
        auto var3_grad = var3_has_value ? grad_output[0] : torch::Tensor();
        torch::autograd::variable_list output = {
            grad_output[0] + grad_output[0] * var2, torch::Tensor(),
            grad_output[0] * mul + grad_output[0] * var1, var3_grad
        };
        return output;
    }
};

torch::Tensor spectral_normalization(torch::Tensor var1, int64_t mul,
                                     torch::Tensor var2,
                                     c10::optional<torch::Tensor> var3) {
    return SpectralNormalization::apply(var1, mul, var2, var3);
}

TORCH_LIBRARY_FRAGMENT(custom, m) {
    m.def("spectral_normalization", spectral_normalization);
}
